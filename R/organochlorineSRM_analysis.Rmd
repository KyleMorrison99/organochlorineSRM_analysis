---
title: "Sixty years since Silent Spring: towards a balanced view of the organochlorine pesticide literature "
author: "Kyle Morrison, Coralie Williams, Lorenzo Ricolfi, Malgorazata Lagisz, Shinichi Nakagawa" 
date: "2023-03-09"
output: 
  rmdformats::robobook:
    code_folding: show
    code_download: true
    toc_depth: 4
editor_options: 
  chunk_output_type: console
---
```{r, include = FALSE}
rm(list = ls())
# knitr setting
knitr::opts_chunk$set(
  message = FALSE,
  warning = FALSE, 
  cache = TRUE,
  echo=TRUE
)
```




In this Rmarkdown document we provide the following workflow:   

- Objective 0. To investigate current literature characteristics such as time trend

- Objective 1 . To explore the various characteristics of the organochlorine pesticides literature such as the pesticides used, the impacts elicited in response and the subjects that were investigated. 

- Objective 2. To investigate current methodological practices within meta-analysis investigating the impacts of organochlorine pesticides. We will investigate how they currently search for existing literature, which effect sizes are used, how they adjust for heterogeneity and how they account for risk of bias. 
 
 - Objective 3 - To investigate current reporting practices in existing meta-analyses examining the impacts of organochlorine pesticides.
 
 - Objective 4 - To investigate the research outputs across different countries and continents and investigate the degree of cross-country collaboration.
 

# **Load packages and data**

## Load Packages 

```{r, results="hide"}
rm(list = ls())
pacman::p_load(tidyverse,
hrbrthemes, 
patchwork,
here,
stringr,
knitr,
formatR,
forcats,
ggplot2,
bibliometrix,
igraph,
stringi,
stringdist,
circlize,
ggalluvial)
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)

```


## Load data

Manually extracted pilot data is stored in five separate **.csv** files representing different aspects of the data (extracted via structured predefined Google Forms - one per table). 

Bibliographic data records are exported from Scopus (including cited references field) in .bib format and locally saved as **scopus.bib**. 



```{r}
sd <- read_csv(here("data","ocp_srm_study_details.csv"), skip = 0)
ocp <- read_csv(here("data", "ocp_srm_ocp_details.csv"), skip = 0)
sub <- read_csv(here("data", "ocp_srm_subject_details.csv"), skip =0)
im <- read_csv(here("data", "ocp_srm_impact_details.csv"), skip =0)
sp <- read_csv(here("data", "ocp_srm_species_details.csv"), skip =0)
bib_sco <- convert2df(here("data","bib_sco.bib"), dbsource = "scopus", format = "bibtex")
```

# Objective 0. To investigate current literature characteristics such as time trend

## Figure 1 - Time trends of number of meta-analysis
```{r}
# Data Transformation
# Count the number of publications per year and calculate cumulative sum
sd1 <- sd %>%
  count(publication_year) %>%
  mutate(n_cumulative = cumsum(n))

# Annual Count Plot
figs1a <- sd1 %>%
  ggplot(aes(x = publication_year, y = n)) +
  geom_col(fill = "#A65475", alpha = 0.7) +
  geom_text(aes(label = n), position = position_stack(vjust = 0.6), fontface = "bold", color = "white", size = 3, hjust = 0.4) +
  scale_x_continuous(breaks = seq(min(sd1$publication_year), max(sd1$publication_year), by = 1)) +
  scale_y_continuous("Annual Article Count", limits = c(0,15)) +
  labs(x = "Year") +
  theme_minimal() +
  theme(panel.grid.major.y = element_line(color = "gray", linetype = "dashed"),
        panel.grid.minor.y = element_blank(),
        axis.line.x = element_line(size = 1.2),
        axis.line.y = element_line(size = 1.2),
        axis.title.x = element_text(size = 14, face = "bold"),
        axis.title.y = element_text(size = 14, face = "bold"),
        axis.text.x = element_text(angle = 45, hjust = 1, size = 10, color = "#666666"),
        axis.text.y = element_text(size = 10, color = "#666666"),
        plot.title = element_text(size = 20, face = "bold"),
        plot.subtitle = element_text(size = 14),
        plot.caption = element_text(size = 10, hjust = 0)) 

# Cumulative Count Plot
figs1b <- sd1 %>%
  ggplot(aes(x = publication_year, y = n_cumulative)) +
  geom_line(color = "#54A76A", size = 1, linetype = "solid") +
  geom_point(shape = 21, size = 3, fill = "#54A76A", stroke = 0) +
  geom_text(aes(label = n_cumulative), hjust = -0.2, vjust = 1, size = 3, color = "black") +
  scale_x_continuous(breaks = seq(min(sd1$publication_year), max(sd1$publication_year), by = 1)) +
  scale_y_continuous("Cumulative Article Count", limits = c(0,120)) +
  labs(x = "Year") +
  theme_minimal() +
  theme(panel.grid.major.y = element_line(color = "gray", linetype = "dashed"),
        panel.grid.minor.y = element_blank(),
        axis.line.x = element_line(size = 1.2),
        axis.line.y = element_line(size = 1.2),
        axis.title.x = element_text(size = 14, face = "bold"),
        axis.title.y = element_text(size = 14, face = "bold"),
        axis.text.x = element_text(angle = 45, hjust = 1, size = 10, color = "#666666"),
        axis.text.y = element_text(size = 10, color = "#666666"),
        plot.title = element_text(size = 20, face = "bold"),
        plot.subtitle = element_text(size = 14),
        plot.caption = element_text(size = 10, hjust = 0)) 

# Combine the two plots
figs1 <- figs1a / figs1b

figs1

```



## Figure x - Total number of meta-analysis per subject 
```{r}
# Join the study and subject datasets
sd_sub <- left_join(sd, sub, by = "study_id")

# Create the annual count plot
fig1a <- sd_sub %>%
  mutate(subjects = strsplit(subject, ",\\s+")) %>%
  unnest(subjects) %>%
  count(publication_year, subjects) %>%
  group_by(subjects = reorder(subjects, n)) %>%
  ggplot(aes(x = as.factor(publication_year), y = n, fill = subjects)) +
  geom_bar(stat = "identity", position = "stack", alpha = 0.7) +
  scale_y_continuous("Annual Article Count", limits = c(0,15)) +
  theme_minimal() +
  labs(x = "Year", y = "Article Count") +
  theme(panel.grid.major.y = element_line(color = "gray", linetype = "dashed"),
        panel.grid.minor.y = element_blank(),
        axis.line.x = element_line(size = 1.2),
        axis.line.y = element_line(size = 1.2),
        axis.title.x = element_text(size = 14, face = "bold"),
        axis.title.y = element_text(size = 14, face = "bold"),
        axis.text.x = element_text(angle = 45, hjust = 1, size = 10, color = "#666666"),
        axis.text.y = element_text(size = 10, color = "#666666"),
        plot.title = element_text(size = 20, face = "bold"),
        plot.subtitle = element_text(size = 14),
        plot.caption = element_text(size = 10, hjust = 0)) +
  scale_fill_brewer(palette = "Dark2") +
  labs(fill = "Subject Category") +
  guides(fill = guide_legend(override.aes = list(size=3)))

# Create the cumulative count plot
fig1b <-  sd_sub %>%
  mutate(subjects = strsplit(subject, ",\\s+")) %>%
  unnest(subjects) %>%
  count(publication_year, subjects) %>%
  group_by(subjects = reorder(subjects, n)) %>%
  mutate(n_cumulative = cumsum(n)) %>%
  ggplot(aes(x = publication_year, y = n_cumulative, fill = subjects)) +
  geom_area(size = 1.2, alpha = 0.7) +
  scale_y_continuous("Cumulative Article Count", limits = c(0,115)) +
  scale_x_continuous(breaks = seq(min(sd_sub$publication_year), max(sd_sub$publication_year), by = 1)) +
  theme_minimal() +
  labs(x = "Year", y = "Cumulative Article Count") +
  theme(panel.grid.major.y = element_line(color = "gray", linetype = "dashed"),
        panel.grid.minor.y = element_blank(),
        axis.line.x = element_line(size = 1.2),
        axis.line.y = element_line(size = 1.2),
        axis.title.x = element_text(size = 14, face = "bold"),
        axis.title.y = element_text(size = 14, face = "bold"),
        axis.text.x = element_text(angle = 45, hjust = 1, size = 10, color = "#666666"),
        axis.text.y = element_text(size = 10, color = "#666666"),
        plot.title = element_text(size = 20, face = "bold"),
        plot.subtitle = element_text(size = 14),
        plot.caption = element_text(size = 10, hjust = 0)) +
  scale_fill_brewer(palette = "Dark2") +
  labs(fill = "Subject") +
  guides(fill = guide_legend(override.aes = list(size=3)))

# Combine the two plots
fig1 <- fig1a /  fig1b

fig1

```


# Objective 1. To characterise the organochlorine pesticides literature such as the pesticides used, the impacts elicited in response and the subjects that were investigated. 

## Figure x - Total count of each organochlorine used in meta-analysis

```{r}
# Transform the data 
ocp_count <-
  ocp %>% 
  separate_rows(ocp, sep = ",\\s+") %>% 
  count(ocp) %>% 
  filter(!is.na(ocp)) %>% # filter out NA 
 filter(ocp != "not reported") %>% 
  arrange(desc(n)) %>% 
  mutate(ocp = ifelse(n <= 3, "other", as.character(ocp))) %>%  ## I NEED TO LIST ALL THE OTHERS HERE WITH THEIR COUNTS
  group_by(ocp) %>% 
  summarise(n =sum(n))

ocp_pct <- ocp_count %>%
  mutate(proportion = n/sum(ocp_count$n),
         percentage = proportion*100)

# Create the count plot 
ocp_count %>%
  ggplot(aes(x = n, y = reorder(ocp, n), fill = "#007030")) +
  geom_bar(stat = "identity", width = 0.6, alpha = 0.7) +
  geom_text(data = ocp_pct, aes(label = paste0("(", round(percentage, 0), "%)")), 
            position = position_dodge(width = 0.9), hjust = -0.9, size = 3, color = "black", fontface = "bold") +
  geom_text(aes(label = n, x = n + 0.5, y = reorder(ocp, n)), vjust = 0.5, hjust = 0, size = 4, color = "black") +
  scale_fill_identity(guide = "none") +
  scale_x_continuous(name = "Article Count", expand = c(0, 0), limits = c(0, 45)) +
  labs(y = NULL) +
  theme_minimal() +
  theme(axis.text.y = element_text(size = 10),
        axis.text.x = element_text(size = 10),
        axis.line.x = element_line(color = "gray", size = 0.5),
        axis.line.y = element_blank(),
        axis.ticks.x = element_blank(),
        axis.ticks.y = element_blank(),
        axis.title.x = element_text(size = 12),
        axis.title.y = element_blank(),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank(),
        legend.position = "none")
 
```

## Figure x - Total proportion of meta-analysis per subject 
note: some meta-analysis may contribute to multiple sections if involve multiple subjects 
```{r}
# Calculate total count for each category
subject_count <- 
  sub %>% 
    separate_rows(subject, sep = ",\\s+") %>% 
    count(subject)

# Calculate proportion and percentage for each category
subject_pct <- subject_count %>%
  mutate(proportion = n/sum(subject_count$n),
         percentage = proportion*100)

# Create the count plot
subject_count %>%
  ggplot(aes(x = n, y = reorder(subject, n), fill = "#007030")) +
  geom_bar(stat = "identity", width = 0.3 , alpha = 0.7) +
  geom_text(data = subject_pct, aes(label = paste0("(", round(percentage, 0), "%)")), 
            position = position_dodge(width = 0.9), hjust = -0.7, size = 3, color = "black", fontface = "bold") +
  geom_text(aes(label = n, x = n + 0.5, y = reorder(subject, n)), vjust = 0.5, hjust = 0, size = 4, color = "black") +
  scale_fill_identity(guide = "none") +
  scale_x_continuous(name = "Article Count", expand = c(0, 0), limits = c(0, 90)) +
  labs(y = NULL) +
  theme_minimal() +
  theme(axis.text.y = element_text(size = 10),
        axis.text.x = element_text(size = 10),
        axis.line.x = element_line(color = "gray", size = 0.5),
        axis.line.y = element_blank(),
        axis.ticks.x = element_blank(),
        axis.ticks.y = element_blank(),
        axis.title.x = element_text(size = 12),
        axis.title.y = element_blank(),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank(),
        legend.position = "none")

```


```{r}
# Calculate total count for each category
impact_count <- 
  im %>% 
    separate_rows(impact, sep = ",\\s+") %>% 
    count(impact) %>% 
  filter(impact != "NA") %>%
  mutate(impact = ifelse(n<= 1, "other", as.character(impact))) %>% 
    group_by(impact) %>%
  summarise(n = sum(n))

# Calculate proportion and percentage for each category
impact_pct <- impact_count %>%
  mutate(proportion = n/sum(impact_count$n),
         percentage = proportion*100)

# Generate a graph
impact_count %>%
  ggplot(aes(x = n, y = reorder(impact, n), fill = "#007030")) +
  geom_bar(stat = "identity", width = 0.3 , alpha = 0.7) +
  geom_text(data = impact_pct, aes(label = paste0("(", round(percentage, 1), "%)")), 
            position = position_dodge(width = 0.9), hjust = -0.7, size = 3, color = "black", fontface = "bold") +
  geom_text(aes(label = n, x = n, y = reorder(impact, n)), vjust = 0.5, hjust = -0.2, size = 4, color = "black") +
  scale_fill_identity(guide = "none") +
  scale_x_continuous(name = "Article Count", limits = c(0, max(impact_count$n)*1.2)) +
  labs(y = NULL) +
  theme_minimal() +
  theme(
    axis.text.y = element_text(size = 10),
    axis.text.x = element_text(size = 10),
    axis.line.x = element_line(color = "gray", size = 0.5),
    axis.line.y = element_blank(),
    axis.ticks.x = element_blank(),
    axis.ticks.y = element_blank(),
    axis.title.x = element_text(size = 12),
    axis.title.y = element_blank(),
    panel.grid.major.y = element_blank(),
    panel.grid.minor.y = element_blank(),
    legend.position = "none"
  )

```

## Alluvial plot of ocp, subjecty and impact 
```{r}

# Transform the data 
df <- im %>%
  left_join(ocp, by = "study_id") %>%
  left_join(sub, by = "study_id") %>%
  separate_rows(subject, sep = ",\\s+") %>% 
  separate_rows(ocp, sep = ",\\s+") %>% 
  separate_rows(impact, sep = ",\\s+") %>%
  mutate(ocp_convert = case_when( # Rename isomers and metabolites to parent chemical (besides DDT, DDD and DDE which are just isomers)
    grepl("DDT", ocp, ignore.case = TRUE) ~ "DDT", 
    grepl("DDD", ocp, ignore.case = TRUE) ~ "DDD", 
    grepl("DDE", ocp, ignore.case = TRUE) ~ "DDE", 
    grepl("HCH|Hexachloro|BHC|Lindane", ocp, ignore.case = TRUE) ~ "Hexachlorohexane", 
    grepl("Chlordane", ocp, ignore.case = TRUE) ~ "Chlordane",  
    grepl("Endosulfan", ocp, ignore.case = TRUE) ~ "Endosulfan", 
    grepl("Nonachlor", ocp, ignore.case = TRUE) ~ "Nonachlore", 
    grepl("Heptachlor", ocp, ignore.case = TRUE) ~ "Heptachlor",
    grepl("TCDD", ocp, ignore.case = TRUE) ~ "TCDD", 
    grepl("Endrin", ocp, ignore.case = TRUE) ~ "Endrin",
    TRUE ~ ocp)) %>%
  filter(!grepl("not reported", ocp_convert, ignore.case = TRUE)) %>%
  group_by(ocp_convert, subject, impact) %>%
  summarise(freq = n(), .groups = 'drop') %>%
  group_by(ocp_convert) %>%
  filter(sum(freq) > 2) %>% # filtered for ocp's with more than two occurrences 
  group_by(impact) %>% 
  filter(sum(freq) > 3) %>% # filter for impacts with more than three occurrences 
  mutate(subject = factor(subject, levels = c("environment", "non-human animal", "human"), ordered = TRUE))


# Plot alluvial plot between ocp, subject and impact 
ggplot(data = df,
       aes(axis1 = ocp_convert, axis2 = subject, axis3 = impact, y = freq)) +
  scale_x_discrete(limits = c("Organochlorine Pesticide", "Subject", "Impact"), expand = c(.05, .10)) +
  xlab("Variables") +
  geom_alluvium(aes(fill = subject)) +
  geom_stratum(width = 1/2, fill = "white", color = "black") +
  geom_text(stat = "stratum", aes(label = after_stat(stratum)), size = 3) +
  theme_minimal() +
  scale_fill_brewer(palette = "Dark2", name = "Subject Category")
```


# Objective 2. To investigate current methodological practices within meta-analysis investigating the impacts of organochlorine pesticides. We will investigate how they currently search for existing literature, which effect sizes are used, how they adjust for heterogeneity and how they account for risk of bias. 

## Figure x - Total count of each database used to search the literature within each meta-analysis
```{r}
# Calculate the total count for each category
database_count <- sd %>% 
  separate_rows(database_search, sep = ",\\s+") %>% 
  count(database_search) %>% 
  filter(database_search != "not reported") %>% 
  arrange(desc(n)) %>% 
  mutate(database_search = ifelse(n<= 2, "other", as.character(database_search))) %>% 
    group_by(database_search) %>%
  summarise(n = sum(n))


# Calculate proportion and percentage for each category
database_pct <- database_count %>%
  mutate(proportion = n / sum(database_count$n),
         percentage = proportion * 100)

# Create the count plot
database_count %>%
  ggplot(aes(x = n, y = reorder(database_search, n), fill = "#007030")) +
  geom_bar(stat = "identity", width = 0.3 , alpha = 0.7) +
  geom_text(data = database_pct, aes(label = paste0("(", round(percentage, 0), "%)")), 
            position = position_dodge(width = 0.9),vjust = 0.5, hjust = -0.7, size = 3, color = "black", fontface = "bold") +
  geom_text(aes(label = n, x = n, y = reorder(database_search, n)), vjust = 0.5, hjust = -0.1, size = 4, color = "black") +
  scale_fill_identity(guide = "none") +
  scale_x_continuous(name = "Article Count", limits = c(0, 60)) +
  labs(y = NULL) +
  theme_minimal() +
  theme(
    axis.text.y = element_text(size = 10),
    axis.text.x = element_text(size = 10),
    axis.line.x = element_line(color = "gray", size = 0.5),
    axis.line.y = element_blank(),
    axis.ticks.x = element_blank(),
    axis.ticks.y = element_blank(),
    axis.title.x = element_text(size = 12),
    axis.title.y = element_blank(),
    panel.grid.major.y = element_blank(),
    panel.grid.minor.y = element_blank(),
    legend.position = "none"
  )


```

 
```{r}
# Data Transformation 
database_alluvial <- sd %>% 
    separate_rows(database_search, sep = ",\\s+") %>%
    separate_rows(Journal_Citation_Report_Category, sep = "/\\s+") %>% 
    filter(!grepl("no category found", Journal_Citation_Report_Category, ignore.case = TRUE)) %>% 
    group_by(Journal_Citation_Report_Category, database_search) %>% 
    count(database_search, Journal_Citation_Report_Category) %>% 
    summarise(freq = n(), .groups = 'drop') %>% 
    group_by(database_search) %>% 
    filter(sum(freq) > 2)  # filtered for scientic databases  with more than two occurrences 

# Create the Alluvial plot
ggplot(database_alluvial, aes(y = freq ,axis1 = Journal_Citation_Report_Category, axis2 = database_search)) +
  scale_x_discrete(limits = c("Journal Citation Report Category", "Database Search"), expand = c(.05, .05)) +
  xlab("Variables") +
  geom_alluvium(aes(fill = Journal_Citation_Report_Category)) +
  geom_stratum(width = 1/8, fill = "white", color = "black") +
  geom_text(stat = "stratum", aes(label = after_stat(stratum)), size = 3) +
  theme_minimal() 



  
```

## Figure x - Total count of each effect size measure used within each meta-analysis
```{r plot effect size used }
# Calculate the total count for each category
effectsize_count <- sd %>% 
  separate_rows(effect_size, sep = ",\\s+") %>% 
  count(effect_size) %>%
  filter(effect_size != "NA") %>%
  mutate(effect_size = ifelse(n<= 2, "other", as.character(effect_size))) %>% 
    group_by(effect_size) %>%
  summarise(n = sum(n))

# Calculate proportion and percentage for each category
effectsize_pct <- effectsize_count %>%
  mutate(proportion = n / sum(effectsize_count$n),
         percentage = proportion * 100)

# Create the count plot
effectsize_count %>%
  ggplot(aes(x = n, y = reorder(effect_size, n), fill = "#007030")) +
  geom_bar(stat = "identity", width = 0.3 , alpha = 0.7) +
  geom_text(data = effectsize_pct, aes(label = paste0("(", round(percentage, 0), "%)")), 
            position = position_dodge(width = 0.9), hjust = -0.7, size = 3, color = "black", fontface = "bold") +
  geom_text(aes(label = n, x = n, y = reorder(effect_size, n)), vjust = 0.5, hjust = -0.2, size = 4, color = "black") +
  scale_fill_identity(guide = "none") +
  scale_x_continuous(name = "Article Count", limits = c(0, 60)) +
  labs(y = NULL) +
  theme_minimal() +
  theme(
    axis.text.y = element_text(size = 10),
    axis.text.x = element_text(size = 10),
    axis.line.x = element_line(color = "gray", size = 0.5),
    axis.line.y = element_blank(),
    axis.ticks.x = element_blank(),
    axis.ticks.y = element_blank(),
    axis.title.x = element_text(size = 12),
    axis.title.y = element_blank(),
    panel.grid.major.y = element_blank(),
    panel.grid.minor.y = element_blank(),
    legend.position = "none"
  )
```

```{r}
# Data Transformation 
effectsize_alluvial <- sd %>% 
    separate_rows(effect_size, sep = ",\\s+") %>%
    separate_rows(Journal_Citation_Report_Category, sep = "/\\s+") %>% 
    filter(!grepl("no category found", Journal_Citation_Report_Category, ignore.case = TRUE)) %>% 
    filter(!is.na(effect_size)) %>%
    group_by(Journal_Citation_Report_Category, effect_size) %>% 
    count(effect_size, Journal_Citation_Report_Category) %>% 
    summarise(freq = n(), .groups = 'drop') %>% 
    group_by(effect_size) #  %>% 
  #   filter(sum(freq) > 2)  # filtered for scientific databases  with more than two occurrences 


# Create the Alluvial plot
ggplot(effectsize_alluvial, aes(y = freq ,axis1 = Journal_Citation_Report_Category, axis2 = effect_size)) +
  scale_x_discrete(limits = c("Journal Citation Report Category", "Effect Size"), expand = c(.05, .05)) +
  xlab("Variables") +
  geom_alluvium(aes(fill = Journal_Citation_Report_Category)) +
  geom_stratum(width = 1/8, fill = "white", color = "black") +
  geom_text(stat = "stratum", aes(label = after_stat(stratum)), size = 3) +
  theme_minimal()

```

## Figure x - Total count of each software used to analyse the data within each meta-analysis
```{r}
# Calculate the total count for each category
software_count <- sd %>% 
  separate_rows(software_analysis, sep = ",\\s+") %>% 
  count(software_analysis) %>%
  filter(software_analysis != "NA") %>%
  mutate(software_analysis = ifelse(n<= 2, "other", as.character(software_analysis))) %>% 
    group_by(software_analysis) %>%
  summarise(n = sum(n))

# Calculate proportion and percentage for each category
software_pct <- software_count %>%
  mutate(proportion = n / sum(software_count$n),
         percentage = proportion * 100)

# Create the count plot
software_count %>%
  ggplot(aes(x = n, y = reorder(software_analysis, n), fill = "#007030")) +
  geom_bar(stat = "identity", width = 0.3 , alpha = 0.7) +
  geom_text(data = software_pct, aes(label = paste0("(", round(percentage, 0), "%)")), 
            position = position_dodge(width = 0.9), hjust = -0.7, size = 3, color = "black", fontface = "bold") +
  geom_text(aes(label = n, x = n, y = reorder(software_analysis, n)), vjust = 0.5, hjust = -0.2, size = 4, color = "black") +
  scale_fill_identity(guide = "none") +
  scale_x_continuous(name = "Article Count", limits = c(0, 60)) +
  labs(y = NULL) +
  theme_minimal() +
  theme(
    axis.text.y = element_text(size = 10),
    axis.text.x = element_text(size = 10),
    axis.line.x = element_line(color = "gray", size = 0.5),
    axis.line.y = element_blank(),
    axis.ticks.x = element_blank(),
    axis.ticks.y = element_blank(),
    axis.title.x = element_text(size = 12),
    axis.title.y = element_blank(),
    panel.grid.major.y = element_blank(),
    panel.grid.minor.y = element_blank(),
    legend.position = "none"
  )


```

```{r}
# Data Transformation 
software_analysis_alluvial <- sd %>% 
    separate_rows(software_analysis, sep = ",\\s+") %>%
    separate_rows(Journal_Citation_Report_Category, sep = "/\\s+") %>% 
    filter(!grepl("no category found", Journal_Citation_Report_Category, ignore.case = TRUE)) %>% 
    filter(!is.na(software_analysis)) %>%
    group_by(Journal_Citation_Report_Category, software_analysis) %>% 
    count(software_analysis, Journal_Citation_Report_Category) %>% 
    summarise(freq = n(), .groups = 'drop') %>% 
    group_by(software_analysis)


# Create the Alluvial plot
ggplot(software_analysis_alluvial, aes(y = freq ,axis1 = Journal_Citation_Report_Category, axis2 = software_analysis)) +
  scale_x_discrete(limits = c("Journal Citation Report Category", "Software Analysis"), expand = c(.05, .05)) +
  xlab("Variables") +
  geom_alluvium(aes(fill = Journal_Citation_Report_Category)) +
  geom_stratum(width = 1/8, fill = "white", color = "black") +
  geom_text(stat = "stratum", aes(label = after_stat(stratum)), size = 3) +
  theme_minimal()

```

## Figure x - Total count of each heterogeneity test used within each meta-analysis
```{r}
# Calculate the total count for each category
heterogeneity_count <- sd %>% 
  separate_rows(heterogeneity_assessment_method, sep = ",\\s+") %>% 
  count(heterogeneity_assessment_method) %>%
  filter(heterogeneity_assessment_method != "NA") %>%
  mutate(heterogeneity_assessment_method = ifelse(n<= 2, "other", as.character(heterogeneity_assessment_method))) %>% 
    group_by(heterogeneity_assessment_method) %>%
  summarise(n = sum(n))

# Calculate proportion and percentage for each category
heterogeneity_pct <- heterogeneity_count %>%
  mutate(proportion = n / sum(heterogeneity_count$n),
         percentage = proportion * 100)

# Create the count plot
heterogeneity_count %>%
  ggplot(aes(x = n, y = reorder(heterogeneity_assessment_method, n), fill = "#007030")) +
  geom_bar(stat = "identity", width = 0.3 , alpha = 0.7) +
  geom_text(data = heterogeneity_pct, aes(label = paste0("(", round(percentage, 0), "%)")), 
            position = position_dodge(width = 0.9), hjust = -0.7, size = 3, color = "black", fontface = "bold") +
  geom_text(aes(label = n, x = n, y = reorder(heterogeneity_assessment_method, n)), vjust = 0.5, hjust = -0.2, size = 4, color = "black") +
  scale_fill_identity(guide = "none") +
  scale_x_continuous(name = "Article Count", limits = c(0, 100)) +
  labs(y = NULL) +
  theme_minimal() +
  theme(
    axis.text.y = element_text(size = 10),
    axis.text.x = element_text(size = 10),
    axis.line.x = element_line(color = "gray", size = 0.5),
    axis.line.y = element_blank(),
    axis.ticks.x = element_blank(),
    axis.ticks.y = element_blank(),
    axis.title.x = element_text(size = 12),
    axis.title.y = element_blank(),
    panel.grid.major.y = element_blank(),
    panel.grid.minor.y = element_blank(),
    legend.position = "none"
  )
```
 
 
```{r}
# Data Transformation 
heterogeneity_alluvial <- sd %>% 
    separate_rows(heterogeneity_assessment_method, sep = ",\\s+") %>%
    separate_rows(Journal_Citation_Report_Category, sep = "/\\s+") %>% 
    filter(!grepl("no category found", Journal_Citation_Report_Category, ignore.case = TRUE)) %>% 
    filter(!is.na(heterogeneity_assessment_method)) %>%
    group_by(Journal_Citation_Report_Category, heterogeneity_assessment_method) %>% 
    count(heterogeneity_assessment_method, Journal_Citation_Report_Category) %>% 
    summarise(freq = n(), .groups = 'drop') %>% 
    group_by(heterogeneity_assessment_method)  

# Create the Alluvial plot
ggplot(heterogeneity_alluvial, aes(y = freq ,axis1 = Journal_Citation_Report_Category, axis2 = heterogeneity_assessment_method)) +
  scale_x_discrete(limits = c("Journal Citation Report Category", "Heterogeneity Assessment Method"), expand = c(.05, .05)) +
  xlab("Variables") +
  geom_alluvium(aes(fill = Journal_Citation_Report_Category)) +
  geom_stratum(width = 1/8, fill = "white", color = "black") +
  geom_text(stat = "stratum", aes(label = after_stat(stratum)), size = 3) +
  theme_minimal()

```
 
## Figure xx - Total count for each sensitivity analysis used in each meta-analysis
```{r}
# Calculate the total count for each category
sensitivity_count <- sd %>% 
  separate_rows(sensitivity_analysis_method, sep = ",\\s+") %>% 
  count(sensitivity_analysis_method) %>%
  filter(sensitivity_analysis_method != "NA") %>%
  mutate(sensitivity_analysis_method = ifelse(n<= 1, "other", as.character(sensitivity_analysis_method))) %>% 
    group_by(sensitivity_analysis_method) %>%
  summarise(n = sum(n))

# Calculate proportion and percentage for each category
sensitivity_pct <- sensitivity_count %>%
  mutate(proportion = n / sum(sensitivity_count$n),
         percentage = proportion * 100)

# Create the count plot
sensitivity_count %>%
  ggplot(aes(x = n, y = reorder(sensitivity_analysis_method, n), fill = "#007030")) +
  geom_bar(stat = "identity", width = 0.3 , alpha = 0.7) +
  geom_text(data = sensitivity_pct, aes(label = paste0("(", round(percentage, 0), "%)")), 
            position = position_dodge(width = 0.9), hjust = -0.7, size = 3, color = "black", fontface = "bold") +
  geom_text(aes(label = n, x = n, y = reorder(sensitivity_analysis_method, n)), vjust = 0.5, hjust = -0.2, size = 4, color = "black") +
  scale_fill_identity(guide = "none") +
  scale_x_continuous(name = "Article Count", limits = c(0, 40)) +
  labs(y = NULL) +
  theme_minimal() +
  theme(
    axis.text.y = element_text(size = 10),
    axis.text.x = element_text(size = 10),
    axis.line.x = element_line(color = "gray", size = 0.5),
    axis.line.y = element_blank(),
    axis.ticks.x = element_blank(),
    axis.ticks.y = element_blank(),
    axis.title.x = element_text(size = 12),
    axis.title.y = element_blank(),
    panel.grid.major.y = element_blank(),
    panel.grid.minor.y = element_blank(),
    legend.position = "none"
  )

```

```{r}
# Data Transformation 
sensitivity_analysis_alluvial <- sd %>% 
    separate_rows(sensitivity_analysis_method, sep = ",\\s+") %>%
    separate_rows(Journal_Citation_Report_Category, sep = "/\\s+") %>% 
    filter(!grepl("no category found", Journal_Citation_Report_Category, ignore.case = TRUE)) %>% 
    filter(!is.na(sensitivity_analysis_method)) %>%
    group_by(Journal_Citation_Report_Category, sensitivity_analysis_method) %>% 
    count(sensitivity_analysis_method, Journal_Citation_Report_Category) %>% 
    summarise(freq = n(), .groups = 'drop') %>% 
    group_by(sensitivity_analysis_method)

# Create the Alluvial plot
ggplot(sensitivity_analysis_alluvial, aes(y = freq ,axis1 = Journal_Citation_Report_Category, axis2 = sensitivity_analysis_method)) +
  scale_x_discrete(limits = c("Journal Citation Report Category", "Sensitivity Analysis Method"), expand = c(.05, .05)) +
  xlab("Variables") +
  geom_alluvium(aes(fill = Journal_Citation_Report_Category)) +
  geom_stratum(width = 1/8, fill = "white", color = "black") +
  geom_text(stat = "stratum", aes(label = after_stat(stratum)), size = 3) +
  theme_minimal()

```

## Figure x - Total count of each type of between study bias investiagted in each meta-analysis
```{r}
# Calculate the total count for each category
bias_type_count <- sd %>% 
  separate_rows(bias_assessment_type, sep = ",\\s+") %>% 
  count(bias_assessment_type) %>%
  filter(bias_assessment_type != "NA") %>%
  group_by(bias_assessment_type) %>%
  summarise(n = sum(n))

# Calculate proportion and percentage for each category
bias_type_pct <- bias_type_count %>%
  mutate(proportion = n / sum(bias_type_count$n),
         percentage = proportion * 100)

# Create the count plot
bias_type_count %>%
  ggplot(aes(x = n, y = reorder(bias_assessment_type, n), fill = "#007030")) +
  geom_bar(stat = "identity", width = 0.3 , alpha = 0.7) +
  geom_text(data = bias_type_pct, aes(label = paste0("(", round(percentage, 0), "%)")), 
            position = position_dodge(width = 0.9), hjust = -0.7, size = 3, color = "black", fontface = "bold") +
  geom_text(aes(label = n, x = n, y = reorder(bias_assessment_type, n)), vjust = 0.5, hjust = -0.2, size = 4, color = "black") +
  scale_fill_identity(guide = "none") +
  scale_x_continuous(name = "Article Count", limits = c(0, 75)) +
  labs(y = NULL) +
  theme_minimal() +
  theme(
    axis.text.y = element_text(size = 10),
    axis.text.x = element_text(size = 10),
    axis.line.x = element_line(color = "gray", size = 0.5),
    axis.line.y = element_blank(),
    axis.ticks.x = element_blank(),
    axis.ticks.y = element_blank(),
    axis.title.x = element_text(size = 12),
    axis.title.y = element_blank(),
    panel.grid.major.y = element_blank(),
    panel.grid.minor.y = element_blank(),
    legend.position = "none"
  )

```


```{r}

# Data Transformation 
bias_assessment_alluvial <- sd %>% 
    separate_rows(bias_assessment_type, sep = ",\\s+") %>%
    separate_rows(Journal_Citation_Report_Category, sep = "/\\s+") %>% 
    filter(!grepl("no category found", Journal_Citation_Report_Category, ignore.case = TRUE)) %>% 
    filter(!is.na(bias_assessment_type)) %>%
    group_by(Journal_Citation_Report_Category, bias_assessment_type) %>% 
    count(bias_assessment_type, Journal_Citation_Report_Category) %>% 
    summarise(freq = n(), .groups = 'drop') %>% 
    group_by(bias_assessment_type)

# Create the Alluvial plot
ggplot(bias_assessment_alluvial, aes(y = freq ,axis1 = Journal_Citation_Report_Category, axis2 = bias_assessment_type)) +
  scale_x_discrete(limits = c("Journal Citation Report Category", "Bias Assessment Type"), expand = c(.05, .05)) +
  xlab("Variables") +
  geom_alluvium(aes(fill = Journal_Citation_Report_Category)) +
  geom_stratum(width = 1/8, fill = "white", color = "black") +
  geom_text(stat = "stratum", aes(label = after_stat(stratum)), size = 3) +
  theme_minimal()


```

## Figure x - Total count for each statistical methodology to investigate within study bias used in each meta-analysis
```{r}
# Calculate the total count for each category
bias_method_count <- sd %>% 
  separate_rows(bias_assessment_method, sep = ",\\s+") %>% 
  count(bias_assessment_method) %>%
  filter(bias_assessment_method != "NA") %>%
    group_by(bias_assessment_method) %>%
  summarise(n = sum(n))

# Calculate proportion and percentage for each category
bias_method_pct <- bias_method_count %>%
  mutate(proportion = n / sum(bias_method_count$n),
         percentage = proportion * 100)

# Create the count plot
bias_method_count %>%
  ggplot(aes(x = n, y = reorder(bias_assessment_method, n), fill = "#007030")) +
  geom_bar(stat = "identity", width = 0.3 , alpha = 0.7) +
  geom_text(data = bias_method_pct, aes(label = paste0("(", round(percentage, 0), "%)")), 
            position = position_dodge(width = 0.9), hjust = -0.7, size = 3, color = "black", fontface = "bold") +
  geom_text(aes(label = n, x = n, y = reorder(bias_assessment_method, n)), vjust = 0.5, hjust = -0.2, size = 4, color = "black") +
  scale_fill_identity(guide = "none") +
  scale_x_continuous(name = "Article Count", limits = c(0, 70)) +
  labs(y = NULL) +
  theme_minimal() +
  theme(
    axis.text.y = element_text(size = 10),
    axis.text.x = element_text(size = 10),
    axis.line.x = element_line(color = "gray", size = 0.5),
    axis.line.y = element_blank(),
    axis.ticks.x = element_blank(),
    axis.ticks.y = element_blank(),
    axis.title.x = element_text(size = 12),
    axis.title.y = element_blank(),
    panel.grid.major.y = element_blank(),
    panel.grid.minor.y = element_blank(),
    legend.position = "none"
  )

```

```{r}
# Data Transformation 
bias_assessment_alluvial <- sd %>% 
    separate_rows(bias_assessment_method, sep = ",\\s+") %>%
    separate_rows(Journal_Citation_Report_Category, sep = "/\\s+") %>% 
    filter(!grepl("no category found", Journal_Citation_Report_Category, ignore.case = TRUE)) %>% 
    filter(!is.na(bias_assessment_method)) %>%
    group_by(Journal_Citation_Report_Category, bias_assessment_method) %>% 
    count(bias_assessment_method, Journal_Citation_Report_Category) %>% 
    summarise(freq = n(), .groups = 'drop') %>% 
    group_by(bias_assessment_method)

# Create the Alluvial plot
ggplot(bias_assessment_alluvial, aes(y = freq ,axis1 = Journal_Citation_Report_Category, axis2 = bias_assessment_method)) +
  scale_x_discrete(limits = c("Journal Citation Report Category", "Bias Assessment Method"), expand = c(.05, .05)) +
  xlab("Variables") +
  geom_alluvium(aes(fill = Journal_Citation_Report_Category)) +
  geom_stratum(width = 1/8, fill = "white", color = "black") +
  geom_text(stat = "stratum", aes(label = after_stat(stratum)), size = 3) +
  theme_minimal()

```

```{r}
# Calculate the total count for each category
rob_method_count <- sd %>% 
  separate_rows(rob_assessment_method, sep = ",\\s+") %>% 
  count(rob_assessment_method) %>%
  filter(rob_assessment_method != "NA") %>%
  group_by(rob_assessment_method) %>%
  summarise(n = sum(n))

# Calculate proportion and percentage for each category
rob_method_pct <- rob_method_count %>%
  mutate(proportion = n / sum(rob_method_count$n),
         percentage = proportion * 100)

# Create the count plot
rob_method_count %>%
  ggplot(aes(x = n, y = reorder(rob_assessment_method, n), fill = "#007030")) +
  geom_bar(stat = "identity", width = 0.3 , alpha = 0.7) +
  geom_text(data = rob_method_pct, aes(label = paste0("(", round(percentage, 0), "%)")), 
            position = position_dodge(width = 0.9), hjust = -0.7, size = 3, color = "black", fontface = "bold") +
  geom_text(aes(label = n, x = n, y = reorder(rob_assessment_method, n)), vjust = 0.5, hjust = -0.2, size = 4, color = "black") +
  scale_fill_identity(guide = "none") +
  scale_x_continuous(name = "Article Count", limits = c(0, 70)) +
  labs(y = NULL) +
  theme_minimal() +
  theme(
    axis.text.y = element_text(size = 10),
    axis.text.x = element_text(size = 10),
    axis.line.x = element_line(color = "gray", size = 0.5),
    axis.line.y = element_blank(),
    axis.ticks.x = element_blank(),
    axis.ticks.y = element_blank(),
    axis.title.x = element_text(size = 12),
    axis.title.y = element_blank(),
    panel.grid.major.y = element_blank(),
    panel.grid.minor.y = element_blank(),
    legend.position = "none"
  )

```

```{r}
# Data Transformation 
robmethod_alluvial <- sd %>% 
    separate_rows(rob_assessment_method, sep = ",\\s+") %>%
   # filter(!is.na(rob_assessment_method)) %>%
    separate_rows(Journal_Citation_Report_Category, sep = "/\\s+") %>%
    filter(!grepl("no category found", Journal_Citation_Report_Category, ignore.case = TRUE)) %>% 
    group_by(Journal_Citation_Report_Category, rob_assessment_method) %>% 
    count(rob_assessment_method, Journal_Citation_Report_Category) %>% 
    summarise(freq = n(), .groups = 'drop') %>% 
    group_by(rob_assessment_method) %>% 
    filter(sum(freq) > 2)  # filtered for scientic databases  with more than two occurrences 


# Create the Alluvial plot
ggplot(robmethod_alluvial, aes(y = freq ,axis1 = Journal_Citation_Report_Category, axis2 = rob_assessment_method)) +
  scale_x_discrete(limits = c("Journal Citation Report Category", "ROB Assessment Method"), expand = c(.05, .05)) +
  xlab("Variables") +
  geom_alluvium(aes(fill = Journal_Citation_Report_Category)) +
  geom_stratum(width = 1/8, fill = "white", color = "black") +
  geom_text(stat = "stratum", aes(label = after_stat(stratum)), size = 3) +
  theme_minimal()

```

## Figure x - Total count for each methodology used to visualise the results of the meta-analsis
```{r}
# Calculate the total count for each category
visualization_count <- sd %>% 
  separate_rows(visualization_method, sep = ",\\s+") %>% 
  count(visualization_method) %>%
  filter(visualization_method != "NA") %>%
  mutate(visualization_method = ifelse(n<= 2, "other", as.character(visualization_method))) %>% 
    group_by(visualization_method) %>%
  summarise(n = sum(n))

# Calculate proportion and percentage for each category
visualization_pct <- visualization_count %>%
  mutate(proportion = n / sum(visualization_count$n),
         percentage = proportion * 100)

# Create the count plot
visualization_count %>%
  ggplot(aes(x = n, y = reorder(visualization_method, n), fill = "#007030")) +
  geom_bar(stat = "identity", width = 0.3 , alpha = 0.7) +
  geom_text(data = visualization_pct, aes(label = paste0("(", round(percentage, 0), "%)")), 
            position = position_dodge(width = 0.9), hjust = -0.7, size = 3, color = "black", fontface = "bold") +
  geom_text(aes(label = n, x = n, y = reorder(visualization_method, n)), vjust = 0.5, hjust = -0.2, size = 4, color = "black") +
  scale_fill_identity(guide = "none") +
  scale_x_continuous(name = "Article Count", limits = c(0, 100)) +
  labs(y = NULL) +
  theme_minimal() +
  theme(
    axis.text.y = element_text(size = 10),
    axis.text.x = element_text(size = 10),
    axis.line.x = element_line(color = "gray", size = 0.5),
    axis.line.y = element_blank(),
    axis.ticks.x = element_blank(),
    axis.ticks.y = element_blank(),
    axis.title.x = element_text(size = 12),
    axis.title.y = element_blank(),
    panel.grid.major.y = element_blank(),
    panel.grid.minor.y = element_blank(),
    legend.position = "none"
  )

```

## Figure x - Total count for each reporting guideline followed in each meta-analysis
```{r}

# Calculate the total count for each category
reporting_guide_count <- sd %>% 
  separate_rows(reporting_standards_type, sep = ",\\s+") %>% 
  count(reporting_standards_type) %>%
  filter(reporting_standards_type != "NA") %>%
  mutate(reporting_standards_type = ifelse(n<= 2, "other", as.character(reporting_standards_type))) %>% 
    group_by(reporting_standards_type) %>%
  summarise(n = sum(n))

# Calculate proportion and percentage for each category
reporting_guide_pct <- reporting_guide_count %>%
  mutate(proportion = n / sum(reporting_guide_count$n),
         percentage = proportion * 100)

# Create the count plot
reporting_guide_count %>%
  ggplot(aes(x = n, y = reorder(reporting_standards_type, n), fill = "#007030")) +
  geom_bar(stat = "identity", width = 0.3 , alpha = 0.7) +
  geom_text(data = reporting_guide_pct, aes(label = paste0("(", round(percentage, 0), "%)")), 
            position = position_dodge(width = 0.9), hjust = -0.7, size = 3, color = "black", fontface = "bold") +
  geom_text(aes(label = n, x = n, y = reorder(reporting_standards_type, n)), vjust = 0.5, hjust = -0.2, size = 4, color = "black") +
  scale_fill_identity(guide = "none") +
  scale_x_continuous(name = "Article Count", limits = c(0, 80)) +
  labs(y = NULL) +
  theme_minimal() +
  theme(
    axis.text.y = element_text(size = 10),
    axis.text.x = element_text(size = 10),
    axis.line.x = element_line(color = "gray", size = 0.5),
    axis.line.y = element_blank(),
    axis.ticks.x = element_blank(),
    axis.ticks.y = element_blank(),
    axis.title.x = element_text(size = 12),
    axis.title.y = element_blank(),
    panel.grid.major.y = element_blank(),
    panel.grid.minor.y = element_blank(),
    legend.position = "none"
  )

```

```{r}
# Data Transformation 
reporting_standards_alluvial <- sd %>% 
    separate_rows(reporting_standards_type, sep = ",\\s+") %>%
    separate_rows(Journal_Citation_Report_Category, sep = "/\\s+") %>%
    filter(!grepl("no category found", Journal_Citation_Report_Category, ignore.case = TRUE)) %>% 
    group_by(Journal_Citation_Report_Category, reporting_standards_type) %>% 
    count(reporting_standards_type, Journal_Citation_Report_Category) %>% 
    summarise(freq = n(), .groups = 'drop') %>% 
    group_by(reporting_standards_type) %>% 
    filter(sum(freq) > 2)  # filtered for scientific databases  with more than two occurrences 


# Create the Alluvial plot
ggplot(reporting_standards_alluvial, aes(y = freq ,axis1 = Journal_Citation_Report_Category, axis2 = reporting_standards_type)) +
  scale_x_discrete(limits = c("Journal Citation Report Category", "Reporting Standards Type"), expand = c(.05, .05)) +
  xlab("Variables") +
  geom_alluvium(aes(fill = Journal_Citation_Report_Category)) +
  geom_stratum(width = 1/8, fill = "white", color = "black") +
  geom_text(stat = "stratum", aes(label = after_stat(stratum)), size = 3) +
  theme_minimal()

```

# Objective 3 - To investigate current reporting practices in existing meta-analyses examining the impacts of organochlorine pesticides.

## Summary plot for CEESAT data

CEESAT results are presented as a percentage of result per question

```{r plot CEESAT summary }

# Start the data manipulation
percent_ceesat_score <- sd %>%
  filter(!is.na(author_year)) %>%
  select(studies = author_year, starts_with("CEE")) %>%
  na.omit() %>%
  pivot_longer(cols = -studies, names_to = "question", values_to = "score") %>%
  group_by(question, score) %>%
  summarise(n = n(), .groups = 'drop') %>%
  mutate(percent = (n/sum(n))*100) %>%
  mutate(across(c(question, score), as.factor)) %>%
  mutate(question = factor(question, levels = rev(levels(question)))) %>%
  mutate(score = factor(score, levels = levels(score)[c(4,1,3,2)]))


# Plot of CEESAT scores
ggplot(data = percent_ceesat_score, aes(x = question, y = percent, fill = score)) +
  geom_col(width = 0.7, position = "fill", color = "black") +
  coord_flip(ylim = c(0, 1)) +
  guides(fill = guide_legend(reverse = TRUE)) +
  scale_fill_manual(values = c("#FF0000","#FFD700","#008000", "#DAA520"), name = "Score:") +
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), 
        panel.background = element_blank()) + 
  ylab("Proportion") + 
  xlab("CEESAT Question")
```

 - **Objective 4.	Bibliometrics: How is synthesized organochlorine pesticide evidence connected?** We will investigate the countries and institutions that are primarily engaged in secondary research on organochlorine pesticides, and analyze the networks that exist between them. By doing so, we hope to gain insights into the collaborative relationships between different institutions and identify any patterns or trends in the distribution of research efforts.

```{r}
fig5a <- biblioAnalysis(bib_sco)
plot(fig5a)
```
## fig5b - co-occurance matrix
```{r}
NetMatrix_keywords <- biblioNetwork(bib_sco, analysis = "co-occurrences", network = "keywords", sep = ";")
fig5b <- networkPlot(NetMatrix_keywords, normalize="association", n = 10, 
                     Title = "Keyword Co-occurrences", type = "fruchterman", 
                     size.cex = TRUE, size = 10, remove.multiple = F, 
                     edgesize = 4, labelsize = 3, label.cex = TRUE, 
                     edges.min = 2, label.n = 9, alpha = 0.3) 
```

## fig5c - thematic map based on keywords
```{r}
par(mfrow=c(1,1), mar=c(0,2,0,2))
fig5c <- thematicMap(bib_sco, field = "ID", n = 2000, minfreq = 5, stemming = FALSE, size = 0.5, n.labels = 1, repel = TRUE)
plot(fig5c$map)

```

## fig 5d - author collaboration network
```{r}
NetMatrix_authors <- biblioNetwork(bib_sco, analysis = "collaboration",  network = "authors", sep = ";")
fig5d <- networkPlot(NetMatrix_authors,  n = 100, 
                                      Title = "Author collaboration", 
                                      type = "auto", size = 4, size.cex = TRUE, 
                                      edgesize = 10, labelsize = 1.1)
```

## fig5e - country publications map
```{r}

bibmap <- metaTagExtraction(bib_sco, Field = "AU1_CO", sep = ";") 
bibmap <- metaTagExtraction(bibmap, Field = "AU_CO", sep = ";") 
#save counts in a data frame
firstcountrycounts <- bibmap %>% 
  group_by(AU1_CO) %>%
  count() %>% 
  filter(!is.na(AU1_CO))  
#load map data
world_map <- map_data("world") %>% 
  filter(! long > 180) #remove countries with longitude >180 to make equal projection-like map without artifacts
# Format country names to match regions on the world map
firstcountrycounts$region <- str_to_title(firstcountrycounts$AU1_CO)
firstcountrycounts$region[firstcountrycounts$region == "Usa"] <- "USA" #Fix "Usa" to "USA" :
firstcountrycounts$region[firstcountrycounts$region == "United Kingdom"] <- "UK" #fix to "UK"
#(firstcountrycounts$region) %in% world_map$region #check matching
## colour all regions on the map:
emptymap <- tibble(region = unique(world_map$region), n = rep(0,length(unique(world_map$region)))) #create table with all counts as 0
fullmap <- left_join(emptymap, firstcountrycounts, by = "region") #join with actual counts table
fullmap$n <- fullmap$n.x + fullmap$n.y # make new column for fixed counts
fullmap$n[is.na(fullmap$n)] <- 0 #change NA to 0 for regions with no counts
fig5e <- fullmap %>% 
  ggplot(aes(fill = n, map_id = region)) +
  geom_map(map = world_map, color = "black") +
  expand_limits(x = world_map$long, y = world_map$lat) +
  coord_map("moll") +
  theme(legend.position="right") +
  scale_fill_gradient(low = "#98FB98", high = "#006400",
                    name = "Score", na.value = "gray70",
 limits = c(1, 20),
      guide = guide_colorbar(direction = "vertical.")) +
  guides(fill = guide_colourbar(barwidth = unit(15, units = "mm"), barheight = unit(20, units = "mm")))
fig5e
```

## Map of europe 
```{r}
fig5f <- fullmap %>% 
  ggplot(aes(fill = n, map_id = region)) +
  geom_map(map = world_map, color = "black") +
  coord_map("moll", ylim = c(30, 75), xlim = c(-25, 45)) + # set limits for Europe
  theme(legend.position = "right") +
  scale_fill_gradient(low = "#98FB98", high = "#006400",
                      name = "Score", na.value = "gray70",
                      limits = c(1, 10),
                      guide = guide_colorbar(direction = "vertical.")) +
  guides(fill = guide_colourbar(barwidth = unit(15, units = "mm"), barheight = unit(20, units = "mm")))

fig5f


```

## fig5f - country collaboration network circle plot
```{r}
# Extract countries from the affiliations
bib_sco2 <- metaTagExtraction(bib_sco, Field = "AU_CO", sep = ";")

# Create a network matrix of collaborations between countries
NetMatrix_country <- biblioNetwork(bib_sco2, analysis = "collaboration", network = "countries", sep = ";")

# Convert the network matrix to a standard matrix
NetMatrix_country <- as.matrix(NetMatrix_country)

# Remove the lower triangle (as this is duplication of info)
NetMatrix_country[lower.tri(NetMatrix_country)] <- 0 

# Change column and row names to title case
colnames(NetMatrix_country) <- str_to_title(colnames(NetMatrix_country))
rownames(NetMatrix_country) <- str_to_title(rownames(NetMatrix_country))

# Change "Usa" to "USA"
colnames(NetMatrix_country)[colnames(NetMatrix_country) == "Usa"] <- "USA"
rownames(NetMatrix_country)[rownames(NetMatrix_country) == "Usa"] <- "USA"

# Change "United Kingdom" to "UK" for easier plotting
colnames(NetMatrix_country)[colnames(NetMatrix_country) == "United Kingdom"] <- "UK"
rownames(NetMatrix_country)[rownames(NetMatrix_country) == "United Kingdom"] <- "UK"

# Define colors for each country
my.cols2 <- c(
  USA = "#377eb8",
  Spain = "#ffff33",
  China = "#e41a1c",
  France = "#999999",
  Canada = "#a6cee3",
  Denmark = "#b2df8a",
  Netherlands = "#377eb8",
  Belgium = "#984ea3",
  UK = "#ffff33",
  Australia = "#4daf4a",
  Brazil = "#4daf4a",
  Germany = "#b2df8a",
  Greece = "#f781bf",
  Korea = "#f781bf",
  Ireland = "#a65628",
  Norway = "#ff7f00",
  Sweden = "#4daf4a",
  Egypt = "#f781bf",
  Italy = "#e41a1c",
  Japan = "#1f78b4",
  Switzerland = "#984ea3",
  Turkey = "#33a02c",
  Austria = "#b2df8a",
  Israel = "#f781bf",
  NewZealand = "#4daf4a",
  Russia = "#999999",
  Singapore = "#b2df8a",
  Portugal = "#984ea3",
  Finland = "#b2df8a",
  Mexico = "#a65628",
  Poland = "#b2df8a",
  SouthAfrica = "#f781bf",
  Argentina = "#ff7f00",
  Chile = "#ff7f00",
  CzechRepublic = "#b2df8a",
  Iceland = "#b2df8a",
  Peru = "#ff7f00",
  Romania = "#fb9a99",
  Serbia = "#fb9a99",
  UAE = "#a65628"
)


# Create a chord diagram of the network matrix
fig5f <- chordDiagram(NetMatrix_country, annotationTrack = "grid", preAllocateTracks = 1, grid.col = my.cols2)

# Add a track to label each sector with its name
circos.trackPlotRegion(track.index = 1, panel.fun = function(x, y) {
  xlim = get.cell.meta.data("xlim")
  ylim = get.cell.meta.data("ylim")
  sector.name = get.cell.meta.data("sector.index")
  circos.text(mean(xlim), ylim[1] + .1, sector.name, facing = "clockwise", niceFacing = TRUE, adj = c(0, 0.5))
  circos.axis(h = "top", labels.cex = 0.5, major.tick.length = 0.5, sector.index = sector.name, track.index = 2)
}, bg.border = NA)

```

## fig5g collaboration matrix with self citation removed
```{r}

diag(NetMatrix_country) <- 0

# Create a chord diagram of the network matrix
fig5g <- chordDiagram(NetMatrix_country, annotationTrack = "grid", preAllocateTracks = 1, grid.col = my.cols2)

# Add a track to label each sector with its name
circos.trackPlotRegion(track.index = 1, panel.fun = function(x, y) {
  xlim = get.cell.meta.data("xlim")
  ylim = get.cell.meta.data("ylim")
  sector.name = get.cell.meta.data("sector.index")
  circos.text(mean(xlim), ylim[1] + .1, sector.name, facing = "clockwise", niceFacing = TRUE, adj = c(0, 0.5))
  circos.axis(h = "top", labels.cex = 0.5, major.tick.length = 0.2, sector.index = sector.name, track.index = 2)
}, bg.border = NA)
```

## fig 5h contitnent collaboration 
```{r}


NetMatrix_continent <- NetMatrix_country
colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "USA"] <- "North America"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "USA"] <- "North America"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "Spain"] <- "Europe"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "Spain"] <- "Europe"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "China"] <- "Asia"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "China"] <- "Asia"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "France"] <- "Europe"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "France"] <- "Europe"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "Canada"] <- "North America"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "Canada"] <- "North America"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "Denmark"] <- "Europe"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "Denmark"] <- "Europe"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "Netherlands"] <- "Europe"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "Netherlands"] <- "Europe"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "Belgium"] <- "Europe"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "Belgium"] <- "Europe"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "UK"] <- "Europe"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "UK"] <- "Europe"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "Australia"] <- "Australia"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "Australia"] <- "Australia"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "Brazil"] <- "South America"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "Brazil"] <- "South America"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "Germany"] <- "Europe"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "Germany"] <- "Europe"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "Finland"] <- "Europe"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "Finland"] <- "Europe"


colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "Greece"] <- "Europe"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "Greece"] <- "Europe"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "Korea"] <- "Asia"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "Korea"] <- "Asia"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "Norway"] <- "Europe"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "Norway"] <- "Europe"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "Sweden"] <- "Europe"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "Sweden"] <- "Europe"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "Egypt"] <- "Africa"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "Egypt"] <- "Africa"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "Italy"] <- "Europe"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "Italy"] <- "Europe"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "Japan"] <- "Asia"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "Japan"] <- "Asia"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "Portugal"] <- "Europe"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "Portugal"] <- "Europe"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "Switzerland"] <- "Europe"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "Switzerland"] <- "Europe"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "Turkey"] <- "Asia"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "Turkey"] <- "Asia"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "India"] <- "Asia"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "India"] <- "Asia"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "Iran"] <- "Asia"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "Iran"] <- "Asia"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "Costa Rica"] <- "North America"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "Costa Rica"] <- "North America"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "Czech Republic"] <- "Europe"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "Czech Republic"] <- "Europe"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "Hong Kong"] <- "Asia"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "Hong Kong"] <- "Asia"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "Iceland"] <- "Europe"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "Iceland"] <- "Europe"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "Ireland"] <- "Europe"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "Ireland"] <- "Europe"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "Mexico"] <- "North America"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "Mexico"] <- "North America"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "Romania"] <- "Europe"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "Romania"] <- "Europe"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "Slovakia"] <- "Europe"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "Slovakia"] <- "Europe"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "Ukraine"] <- "Europe"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "Ukraine"] <- "Europe"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "Australia"] <- "Oceania"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "Australia"] <- "Oceania"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "Kazakhstan"] <- "Asia"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "Kazakhstan"] <- "Asia"


# collapsing
merge_matrix <- t(rowsum(t(NetMatrix_continent), group = colnames(NetMatrix_continent), na.rm = T))
merge_matrix2 <- rowsum(merge_matrix, group = rownames(merge_matrix))
# remove diagonal elements
diag(merge_matrix2) <- 0
# chord plot
chordDiagramFromMatrix(merge_matrix2)

# Define colors for each continent
my.cols2 <- c(
  Africa = "#CC79A7",
  NorthAmerica = "#F0E442",
  Asia = "#0072B2",
  Europe = "#E69F00",
  Oceania = "#009E73",
  SouthAmerica = "#D55E00"
)


# Create a chord diagram of the network matrix
fig5h <- chordDiagram(merge_matrix2, annotationTrack = "grid", preAllocateTracks = 1)
# Add a track to label each sector with its name
circos.trackPlotRegion(track.index = 1, panel.fun = function(x, y) {
  xlim = get.cell.meta.data("xlim")
  ylim = get.cell.meta.data("ylim")
  sector.name = get.cell.meta.data("sector.index")
  circos.text(mean(xlim), ylim[1] + 0.2, sector.name, facing = "clockwise", niceFacing = TRUE, adj = c(0, 0.5))
  circos.axis(h = "top", labels.cex = 0.5, major.tick.length = 0.2, sector.index = sector.name, track.index = 2)
}, bg.border = NA)

```



```{r most cited articles and authors}

CR <- citations(bib_sco, field = "article", sep = ";") #list of most cited articles
 cbind(CR$Cited[1:10]) #ten most cited articles
 
CR <- citations(bib_sco, field = "author", sep = ";")
cbind(CR$Cited[1:10]) #ten most cited authors
``` 

```{r bibliometric coupling network}
NetMatrix_coupling <- biblioNetwork(bib_sco, analysis = "coupling", network = "references", sep = "; ")
NetMatrix_coupling_plot <- networkPlot(NetMatrix_coupling, n = 20, 
                                       Title = "Paper co-citation", type = "fruchterman", size=T, 
                                       remove.multiple=FALSE, labelsize=0.8,edgesize = 5)
```


