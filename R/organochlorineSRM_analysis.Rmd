---
title: "Sixty years since Silent Spring: towards a balanced view of the organochlorine pesticide literature "
author: "Kyle Morrison, Coralie Williams, Lorenzo Ricolfi, Malgorazata Lagisz, Shinichi Nakagawa" 
date: "2023-03-09"
output: 
  rmdformats::robobook:
    code_folding: show
    code_download: true
    toc_depth: 4
editor_options: 
  chunk_output_type: console
---
```{r setup, include = FALSE}
rm(list = ls())
# knitr setting
knitr::opts_chunk$set(
  message = FALSE,
  warning = FALSE, 
  cache = TRUE,
  echo=TRUE
)
```




In this Rmarkdown document we provide the following workflow:   

- Objective 0. To investigate current literature characteristics such as time trend

- Objective 1 . To explore the various characteristics of the organochlorine pesticides literature such as the pesticides used, the impacts elicited in response and the subjects that were investigated. 

- Objective 2. To investigate current methodological practices within meta-analysis investigating the impacts of organochlorine pesticides. We will investigate how they currently search for existing literature, which effect sizes are used, how they adjust for heterogeneity and how they account for risk of bias. 
 
 - Objective 3 - To investigate current reporting practices in existing meta-analyses examining the impacts of organochlorine pesticides.
 
 - Objective 4 - To investigate the research outputs across different countries and continents and investigate the degree of cross-country collaboration.
 

# **Load packages and data**

## Load Packages 

```{r setup, results="hide"}
rm(list = ls())
pacman::p_load(tidyverse,
hrbrthemes, 
patchwork,
here,
stringr,
knitr,
formatR,
forcats,
ggplot2,
bibliometrix,
igraph,
stringi,
stringdist,
circlize)
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)

```


## Load data

Manually extracted pilot data is stored in five separate **.csv** files representing different aspects of the data (extracted via structured predefined Google Forms - one per table). 

Bibliographic data records are exported from Scopus (including cited references field) in .bib format and locally saved as **scopus.bib**. 



```{r load pilot data}
sd <- read_csv(here("data","ocp_srm_study_details.csv"), skip = 0)
ocp <- read_csv(here("data", "ocp_srm_ocp_details.csv"), skip = 0)
sub <- read_csv(here("data", "ocp_srm_subject_details.csv"), skip =0)
im <- read_csv(here("data", "ocp_srm_impact_details.csv"), skip =0)
sp <- read_csv(here("data", "ocp_srm_species_details.csv"), skip =0)
bib_sco <- convert2df(here("data","bib_sco.bib"), dbsource = "scopus", format = "bibtex")
```

# Objective 0. To investigate current literature characteristics such as time trend

## Figure 1 - Time trends of number of meta-analysis
```{r}
# Transform the data
sd1 <- sd %>%
  count(publication_year) %>%
  mutate(n_cumulative = cumsum(n))

# Calculate the maximum y scale for the secondary axis
max_scale <- max(sd$n)

# Create the annual count plot
annual_plot <- sd1 %>%
  ggplot(aes(x = publication_year, y = n)) +
  geom_col(fill = "#A65475", alpha = 0.7) +
  geom_text(aes(label = n), position = position_stack(vjust = 0.6), fontface = "bold", color = "white", size = 3, hjust = 0.4) +
  scale_x_continuous(breaks = seq(min(sd1$publication_year), max(sd1$publication_year), by = 1)) +
  scale_y_continuous("Annual Article Count", limits = c(0,15)) +
  labs(x = "Year") +
  theme_minimal() +
  theme( 
    panel.grid.major.y = element_line(color = "gray", linetype = "dashed"),
    panel.grid.minor.y = element_blank(),
    axis.line.x = element_line(size = 1.2),
    axis.line.y = element_line(size = 1.2),
    axis.title.x = element_text(size = 14, face = "bold"),
    axis.title.y = element_text(size = 14, face = "bold"),
    axis.text.x = element_text(angle = 45, hjust = 1, size = 10, color = "#666666"),
    axis.text.y = element_text(size = 10, color = "#666666"),
    plot.title = element_text(size = 20, face = "bold"),
    plot.subtitle = element_text(size = 14),
    plot.caption = element_text(size = 10, hjust = 0)
  ) 

# Create the cumulative count plot
cumulative_plot <- sd1 %>%
  ggplot(aes(x = publication_year, y = n_cumulative)) +
  geom_line(color = "#54A76A", size = 1, linetype = "solid") +
  geom_point(shape = 21, size = 3, fill = "#54A76A", stroke = 0) +
  geom_text(aes(label = n_cumulative), hjust = -0.2, vjust = 1, size = 3, color = "black") +
  scale_x_continuous(breaks = seq(min(sd1$publication_year), max(sd1$publication_year), by = 1)) +
  scale_y_continuous("Cumulative Article Count", limits = c(0,120)) +
  labs(x = "Year") +
  theme_minimal() +
  theme( 
    panel.grid.major.y = element_line(color = "gray", linetype = "dashed"),
    panel.grid.minor.y = element_blank(),
    axis.line.x = element_line(size = 1.2),
    axis.line.y = element_line(size = 1.2),
    axis.title.x = element_text(size = 14, face = "bold"),
    axis.title.y = element_text(size = 14, face = "bold"),
    axis.text.x = element_text(angle = 45, hjust = 1, size = 10, color = "#666666"),
    axis.text.y = element_text(size = 10, color = "#666666"),
    plot.title = element_text(size = 20, face = "bold"),
    plot.subtitle = element_text(size = 14),
    plot.caption = element_text(size = 10, hjust = 0)
  )

# Combine the two plots
fig1 <- annual_plot / cumulative_plot

fig1
```



## Figure x - Total number of meta-analysis per subject 
```{r}
sd_sub <- left_join(sd, sub, by = "study_id")

# Create the annual count plot
subject_bar_plot <- sd_sub %>%
  mutate(subjects = strsplit(subject, ",\\s+")) %>%
  unnest(subjects) %>%
  count(publication_year, subjects) %>%
  group_by(subjects = reorder(subjects, n)) %>%
  ggplot(aes(x = as.factor(publication_year), y = n, fill = subjects)) +
  geom_bar(stat = "identity", position = "stack", alpha = 0.7) +
  theme_minimal() +
  labs(x = "Year", y = "Article Count") +
  theme(panel.grid.major.y = element_line(color = "gray", linetype = "dashed"),
        panel.grid.minor.y = element_blank(),
        axis.line.x = element_line(size = 1.2),
        axis.line.y = element_line(size = 1.2),
        axis.title.x = element_text(size = 14, face = "bold"),
        axis.title.y = element_text(size = 14, face = "bold"),
        axis.text.x = element_text(angle = 45, hjust = 1, size = 10, color = "#666666"),
        axis.text.y = element_text(size = 10, color = "#666666"),
        plot.title = element_text(size = 20, face = "bold"),
        plot.subtitle = element_text(size = 14),
        plot.caption = element_text(size = 10, hjust = 0)) +
  scale_fill_brewer(palette = "Dark2") +
  labs(fill = "Subject") +
  guides(fill = guide_legend(override.aes = list(size=4)))

# Create the cumulative count plot
subject_cumulative_plot <-  sd_sub %>%
  mutate(subjects = strsplit(subject, ",\\s+")) %>%
  unnest(subjects) %>%
  count(publication_year, subjects) %>%
  group_by(subjects = reorder(subjects, n)) %>%
  mutate(n_cumulative = cumsum(n)) %>%
  ggplot(aes(x = publication_year, y = n_cumulative, fill = subjects)) +
  geom_area(size = 1.2, alpha = 0.7) +
  scale_x_continuous(breaks = seq(min(sd_sub$publication_year), max(sd_sub$publication_year), by = 1)) +
  theme_minimal() +
  labs(x = "Year", y = "Cumulative Article Count") +
  theme(panel.grid.major.y = element_line(color = "gray", linetype = "dashed"),
        panel.grid.minor.y = element_blank(),
        axis.line.x = element_line(size = 1.2),
        axis.line.y = element_line(size = 1.2),
        axis.title.x = element_text(size = 14, face = "bold"),
        axis.title.y = element_text(size = 14, face = "bold"),
        axis.text.x = element_text(angle = 45, hjust = 1, size = 10, color = "#666666"),
        axis.text.y = element_text(size = 10, color = "#666666"),
        plot.title = element_text(size = 20, face = "bold"),
        plot.subtitle = element_text(size = 14),
        plot.caption = element_text(size = 10, hjust = 0)) +
  scale_fill_brewer(palette = "Dark2") +
  labs(fill = "Subject") +
  guides(fill = guide_legend(override.aes = list(size=4)))

figs1 <- subject_bar_plot /  subject_cumulative_plot
figs1

```


# Objective 1.	Mapping: What evidence on organochlorine pesticides has been synthesized?

## Figure x - Total count of each organochlorine used in meta-analysis

```{r}


ocp_count <-
  ocp %>% 
  separate_rows(ocp, sep = ", ") %>% 
  count(ocp) %>% 
  filter(!is.na(ocp)) %>% # filter out NA 
 filter(ocp != "not reported") %>% 
  arrange(desc(n)) %>% 
  mutate(ocp = ifelse(n <= 5, "other",
  as.character(ocp))) %>% 
  
## I NEED TO LIST ALL THE OTHERS HERE WITH THEIR COUNTS
  group_by(ocp) %>% 
  summarise(n =sum(n))

ocp_count %>%
  ggplot(aes(x = n, y = reorder(ocp, n), color = "#007030")) +
  geom_point(stat = "identity", size = 6, shape = 21,fill = "#007030", color = "white") +
  geom_segment(aes(xend = 0, yend = reorder(ocp, n))) +
  scale_color_identity(guide = "none") +
  scale_x_continuous(name = "Count", expand = c(0, 0), limits = c(0, 75)) +
  labs(y = NULL) +
  theme_minimal() +
  theme(axis.text.y = element_text(size = 10),
        axis.text.x = element_text(size = 10),
        axis.line.x = element_line(color = "gray", size = 0.5),
        axis.line.y = element_blank(),
        axis.ticks.x = element_blank(),
        axis.ticks.y = element_blank(),
        axis.title.x = element_text(size = 12),
        axis.title.y = element_blank(),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank(),
        legend.position = "none") +
  geom_text(aes(label = n, x = n + 4, y = reorder(ocp, n)),
            vjust = 0.5, hjust = 0, size = 5, color = "black")

figy
```





## Figure x - Total proportion of meta-analysis per subject 
note: some meta-analysis may contribute to multiple sections if involve multiple subjects 
```{r}
# Calculate total count for each category
total_subject_count <- sub %>% count(subject)

# Calculate proportion and percentage for each category
subject_pct <- sub %>%
  separate_rows(subject, sep = ",\\s*") %>% 
  count(subject) %>%
  mutate(proportion = n/sum(total_subject_count$n),
         percentage = proportion*100)

subject_pct %>% 
ggplot( aes(x = percentage, y = reorder(subject, percentage), color = "#007030")) +
  geom_point(stat = "identity", size = 6, shape = 21, fill = "#007030", color = "white") +
  geom_segment(aes(xend = 0, yend = reorder(subject, percentage))) +
  scale_color_identity(guide = "none") +
  scale_x_continuous(name = "Percentage", expand = c(0, 0), limits = c(0, 100)) +
  labs(y = NULL) +
  theme_minimal() +
  theme(axis.text.y = element_text(size = 10),
        axis.text.x = element_text(size = 10),
        axis.line.x = element_line(color = "gray", size = 0.5),
        axis.line.y = element_blank(),
        axis.ticks.x = element_blank(),
        axis.ticks.y = element_blank(),
        axis.title.x = element_text(size = 12),
        axis.title.y = element_blank(),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank(),
        legend.position = "none") +
  geom_text(aes(label = paste0(round(percentage, 1), "%"), x = percentage + 2, y = reorder(subject, percentage)),
            vjust = 0.5, hjust = 0, size = 5, color = "black")



```

# Objective 2. To investigate current methodological practices within meta-analysis investigating the impacts of organochlorine pesticides. We will investigate how they currently search for existing literature, which effect sizes are used, how they adjust for heterogeneity and how they account for risk of bias. 

## Figure x - Total count of each database used to search the literature within each meta-analysis

```{r}
database_count <- sd %>% 
separate_rows(database_search, sep = ",\\s*") %>% 
  count(database_search) %>% 
  filter(database_search != "not reported") %>% # filter out NA 
  arrange(desc(n)) %>% 
  filter(n>2)

database_count %>%
  ggplot(aes(x = n, y = reorder(database_search,n), color = "#007030")) +
  geom_point(stat = "identity", size = 6, shape = 21,fill = "#007030", color = "white") +
  geom_segment(aes(xend = 0, yend = reorder(database_search,n))) +
  scale_color_identity(guide = "none") +
  scale_x_continuous(name = "Article Count", expand = c(0, 0), limits = c(0, 60)) +
  labs(y = NULL) +
  theme_minimal() +
  theme(axis.text.y = element_text(size = 10),
        axis.text.x = element_text(size = 10),
        axis.line.x = element_line(color = "gray", size = 0.5),
        axis.line.y = element_blank(),
        axis.ticks.x = element_blank(),
        axis.ticks.y = element_blank(),
        axis.title.x = element_text(size = 12),
        axis.title.y = element_blank(),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank(),
        legend.position = "none") +
  geom_text(data = database_count , aes(label = n, x = n + 2, y = reorder(database_search,n)),
            vjust = 0.5, hjust = 0, size = 5, color = "black")

```


## Figure x - Total count of each effect size measure used within each meta-analysis

```{r plot effect size used }
effectsize_count <- 
  sd %>% 
  separate_rows(effect_size, sep = ",\\s*") %>% 
  count(effect_size) %>% 
    filter(effect_size != "NA", n>1) %>% 
  arrange(desc(n))

effectsize_count %>%
  ggplot(aes(x = n, y = reorder(effect_size,n), color = "#007030")) +
  geom_point(stat = "identity", size = 6, shape = 21,fill = "#007030", color = "white") +
  geom_segment(aes(xend = 0, yend = reorder(effect_size,n))) +
  scale_color_identity(guide = "none") +
  scale_x_continuous(name = "Article Count", expand = c(0, 0), limits = c(0, 70)) +
  labs(y = NULL) +
  theme_minimal() +
  theme(axis.text.y = element_text(size = 10),
        axis.text.x = element_text(size = 10),
        axis.line.x = element_line(color = "gray", size = 0.5),
        axis.line.y = element_blank(),
        axis.ticks.x = element_blank(),
        axis.ticks.y = element_blank(),
        axis.title.x = element_text(size = 12),
        axis.title.y = element_blank(),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank(),
        legend.position = "none") +
  geom_text(data = effectsize_count, aes(label = n, x = n + 2, y = reorder(effect_size,n)),
            vjust = 0.5, hjust = 0, size = 5, color = "black")


```

## Figure x - Total count of each software used to analyse the data within each meta-analysis

```{r}
software_count <- 
  msp%>% 
  separate_rows(software_analysis, sep = ",\\s*") %>% 
  count(software_analysis) %>% 
    filter(software_analysis != "NA") %>% 
  arrange(desc(n))

software_count %>%
  ggplot(aes(x = n, y = reorder(software_analysis,n), color = "#007030")) +
  geom_point(stat = "identity", size = 6, shape = 21, fill = "#007030", color = "white") +
  geom_segment(aes(xend = 0, yend = reorder(software_analysis,n))) +
  scale_color_identity(guide = "none") +
  scale_x_continuous(name = "Article Count", expand = c(0, 0), limits = c(0, 50)) +
  labs(y = NULL) +
  theme_minimal() +
  theme(axis.text.y = element_text(size = 10),
        axis.text.x = element_text(size = 10),
        axis.line.x = element_line(color = "gray", size = 0.5),
        axis.line.y = element_blank(),
        axis.ticks.x = element_blank(),
        axis.ticks.y = element_blank(),
        axis.title.x = element_text(size = 12),
        axis.title.y = element_blank(),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank(),
        legend.position = "none") +
  geom_text(data = software_count, aes(label = n, x = n + 2, y = reorder(software_analysis,n)),
            vjust = 0.5, hjust = 0, size = 5, color = "black")

```

## Figure x - Total count of each heterogeneity test used within each meta-analysis
```{r}
heterogeneity_count <-  
  sd %>% 
  separate_rows(heterogeneity_assessment_method, sep = ",\\s*") %>% 
  count(heterogeneity_assessment_method) %>% 
    filter(heterogeneity_assessment_method != "NA") %>% 
  arrange(desc(n))

heterogeneity_count %>%
  ggplot(aes(x = n, y = reorder(heterogeneity_assessment_method,n), color = "#007030")) +
  geom_point(stat = "identity", size = 6, shape = 21, fill = "#007030", color = "white") +
  geom_segment(aes(xend = 0, yend = reorder(heterogeneity_assessment_method,n))) +
  scale_color_identity(guide = "none") +
  scale_x_continuous(name = "Article Count", expand = c(0, 0), limits = c(0, 100)) +
  labs(y = NULL) +
  theme_minimal() +
  theme(axis.text.y = element_text(size = 10),
        axis.text.x = element_text(size = 10),
        axis.line.x = element_line(color = "gray", size = 0.5),
        axis.line.y = element_blank(),
        axis.ticks.x = element_blank(),
        axis.ticks.y = element_blank(),
        axis.title.x = element_text(size = 12),
        axis.title.y = element_blank(),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank(),
        legend.position = "none") +
  geom_text(data = heterogeneity_count, aes(label = n, x = n + 2, y = reorder(heterogeneity_assessment_method,n)),
            vjust = 0.5, hjust = 0, size = 5, color = "black")


```
 

## Figure xx - Total count for each sensitivity analysis used in each meta-analysis
```{r}

sensitivity_count <-
  sd %>% 
  separate_rows(sensitivity_analysis_method, sep = ",\\s*") %>% 
  count(sensitivity_analysis_method) %>% 
    filter(sensitivity_analysis_method != "NA") %>% 
  arrange(desc(n))

sensitivity_count %>%
  ggplot(aes(x = n, y = reorder(sensitivity_analysis_method,n), color = "#007030")) +
  geom_point(stat = "identity", size = 6, shape = 21, fill = "#007030", color = "white") +
  geom_segment(aes(xend = 0, yend = reorder(sensitivity_analysis_method,n))) +
  scale_color_identity(guide = "none") +
  scale_x_continuous(name = "Article Count", expand = c(0, 0), limits = c(0, 70)) +
  labs(y = NULL) +
  theme_minimal() +
  theme(axis.text.y = element_text(size = 10),
        axis.text.x = element_text(size = 10),
        axis.line.x = element_line(color = "gray", size = 0.5),
        axis.line.y = element_blank(),
        axis.ticks.x = element_blank(),
        axis.ticks.y = element_blank(),
        axis.title.x = element_text(size = 12),
        axis.title.y = element_blank(),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank(),
        legend.position = "none") +
  geom_text(data = sensitivity_count, aes(label = n, x = n + 2, y = reorder(sensitivity_analysis_method,n)),
            vjust = 0.5, hjust = 0, size = 5, color = "black")


```


## Figure x - Total count of each type of between study bias investiagted in each meta-analysis
```{r}
bias_type_count <- 
  sd %>% 
  separate_rows(bias_assessment_type, sep = ",\\s*") %>% 
  count(bias_assessment_type) %>% 
    filter(bias_assessment_type!= "NA") %>% 
  arrange(desc(n))
  
bias_type_count %>%
  ggplot(aes(x = n, y = reorder(bias_assessment_type,n), color = "#007030")) +
  geom_point(stat = "identity", size = 6, shape = 21, fill = "#007030", color = "white") +
  geom_segment(aes(xend = 0, yend = reorder(bias_assessment_type,n))) +
  scale_color_identity(guide = "none") +
  scale_x_continuous(name = "Article Count", expand = c(0, 0), limits = c(0, 75)) +
  labs(y = NULL) +
  theme_minimal() +
  theme(axis.text.y = element_text(size = 10),
        axis.text.x = element_text(size = 10),
        axis.line.x = element_line(color = "gray", size = 0.5),
        axis.line.y = element_blank(),
        axis.ticks.x = element_blank(),
        axis.ticks.y = element_blank(),
        axis.title.x = element_text(size = 12),
        axis.title.y = element_blank(),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank(),
        legend.position = "none") +
  geom_text(data = bias_type_count, aes(label = n, x = n + 2, y = reorder(bias_assessment_type,n)),
            vjust = 0.5, hjust = 0, size = 5, color = "black")


```


## Figure x - Total count for each statistical methodology to investigate within study bias used in each meta-analysis
```{r}
bias_method_count <- 
  sd %>% 
  separate_rows(bias_assessment_method, sep = ",\\s*") %>% 
  count(bias_assessment_method) %>% 
    filter(bias_assessment_method!= "NA") %>% 
  arrange(desc(n))
  
bias_method_count %>%
  ggplot(aes(x = n, y = reorder(bias_assessment_method,n), color = "#007030")) +
  geom_point(stat = "identity", size = 6, shape = 21, fill = "#007030", color = "white") +
  geom_segment(aes(xend = 0, yend = reorder(bias_assessment_method,n))) +
  scale_color_identity(guide = "none") +
  scale_x_continuous(name = "Article Count", expand = c(0, 0), limits = c(0, 70)) +
  labs(y = NULL) +
  theme_minimal() +
  theme(axis.text.y = element_text(size = 10),
        axis.text.x = element_text(size = 10),
        axis.line.x = element_line(color = "gray", size = 0.5),
        axis.line.y = element_blank(),
        axis.ticks.x = element_blank(),
        axis.ticks.y = element_blank(),
        axis.title.x = element_text(size = 12),
        axis.title.y = element_blank(),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank(),
        legend.position = "none") +
  geom_text(data = bias_method_count, aes(label = n, x = n + 2, y = reorder(bias_assessment_method,n)),
            vjust = 0.5, hjust = 0, size = 5, color = "black")
```


## Figure x - Total count for each methodology used to visualise the results of the meta-analsis
```{r}
vizualisation_count <- 
  sd %>% 
  separate_rows(visualization_method, sep = ",\\s*") %>% 
  count(visualization_method) %>% 
   filter(visualization_method!= "NA") %>% 
  arrange(desc(n))

vizualisation_count %>%
  ggplot(aes(x = n, y = reorder(visualization_method,n), color = "#007030")) +
  geom_point(stat = "identity", size = 6, shape = 21, fill = "#007030", color = "white") +
  geom_segment(aes(xend = 0, yend = reorder(visualization_method,n))) +
  scale_color_identity(guide = "none") +
  scale_x_continuous(name = "Article Count", expand = c(0, 0), limits = c(0, 100)) +
  labs(y = NULL) +
  theme_minimal() +
  theme(axis.text.y = element_text(size = 10),
        axis.text.x = element_text(size = 10),
        axis.line.x = element_line(color = "gray", size = 0.5),
        axis.line.y = element_blank(),
        axis.ticks.x = element_blank(),
        axis.ticks.y = element_blank(),
        axis.title.x = element_text(size = 12),
        axis.title.y = element_blank(),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank(),
        legend.position = "none") +
  geom_text(data = vizualisation_count, aes(label = n, x = n + 2, y = reorder(visualization_method,n)),
            vjust = 0.5, hjust = 0, size = 5, color = "black")
```


## Figure x - Total count for each reporting guideline followed in each meta-analysis
```{r}

reporting_guide_count <- 
  sd %>% 
  separate_rows(reporting_standards_type, sep = ",\\s*") %>% 
  count(reporting_standards_type) %>% 
   filter(reporting_standards_type!= "NA") %>% 
  arrange(desc(n))

reporting_guide_count %>%
  ggplot(aes(x = n, y = reorder(reporting_standards_type,n), color = "#007030")) +
  geom_point(stat = "identity", size = 6, shape = 21, fill = "#007030", color = "white") +
  geom_segment(aes(xend = 0, yend = reorder(reporting_standards_type,n))) +
  scale_color_identity(guide = "none") +
  scale_x_continuous(name = "Article Count", expand = c(0, 0), limits = c(0, 80)) +
  labs(y = NULL) +
  theme_minimal() +
  theme(axis.text.y = element_text(size = 10),
        axis.text.x = element_text(size = 10),
        axis.line.x = element_line(color = "gray", size = 0.5),
        axis.line.y = element_blank(),
        axis.ticks.x = element_blank(),
        axis.ticks.y = element_blank(),
        axis.title.x = element_text(size = 12),
        axis.title.y = element_blank(),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank(),
        legend.position = "none") +
  geom_text(data = reporting_guide_count, aes(label = n, x = n + 2, y = reorder(reporting_standards_type,n)),
            vjust = 0.5, hjust = 0, size = 5, color = "black")
```

- **Objective 2.	Critical appraisal: How robust are syntheses of organochlorine pesticide evidence?** We will examine the included meta-analyses for their reporting quality and potential biases, in order to assess reliability of reviewsâ€™ conclusions, reveal syntheses that should be re-done, and highlight the aspects of review methodology that need to be improved.


## Summary plot for CEESAT data

CEESAT results are presented as a percentage of result per question

```{r plot CEESAT summary }

studies <- sd$author_year 

ceesat_table <- sd %>%  
  filter(studies!="NA") %>% 
  select(starts_with("CEE"))

ceesat_studies_wide <- tibble(studies,ceesat_table)

ceesat_studies_wide <- na.omit(ceesat_studies_wide)

ceesat_studies_long<- pivot_longer(ceesat_studies_wide, cols = 2:17, names_to =  "question", values_to = "score")         

#calculating the proportions of scores within each questions 
count_ceesat_score <- ceesat_studies_long %>% count(score, by = question) 
percent_ceesat_score <- count_ceesat_score %>% mutate(percent = (n/sum(n))*100)
percent_ceesat_score <- percent_ceesat_score %>% rename(question = by)
percent_ceesat_score$question <- as.factor(percent_ceesat_score$question)
percent_ceesat_score$question <- factor(percent_ceesat_score$question, levels(percent_ceesat_score$question)[length(percent_ceesat_score$question):1]) #reverse the order of questions
percent_ceesat_score$score <- as.factor(percent_ceesat_score$score)
percent_ceesat_score$score <- factor(percent_ceesat_score$score, levels(percent_ceesat_score$score)[c(1,4,2,3)]) #set the order of levels for assessment scores:


# Plot of CEESAT scores
ggplot(data = percent_ceesat_score, x = question, y = percent) +
  geom_col(mapping = aes(x = question, y = percent, fill = score), width = 0.7,
           position = "fill", color = "black") +
  coord_flip(ylim = c(0, 1)) +
  guides(fill = guide_legend(reverse = TRUE)) +
  scale_fill_manual(values = c("#E74C3C","#FFD700","#7BCB6F", "#FFA500"), name = "Score:") +
  theme(panel.grid.major = element_blank(),panel.grid.minor = element_blank(),panel.background = element_blank()) + 
  ylab("Proportion") + xlab("CEESAT Question")


```






 - **Objective 4.	Bibliometrics: How is synthesized organochlorine pesticide evidence connected?** We will investigate the countries and institutions that are primarily engaged in secondary research on organochlorine pesticides, and analyze the networks that exist between them. By doing so, we hope to gain insights into the collaborative relationships between different institutions and identify any patterns or trends in the distribution of research efforts.

```{r}
fig5a <- biblioAnalysis(bib_sco)
plot(fig5a)
```
## fig5b - co-occurance matrix
```{r}
NetMatrix_keywords <- biblioNetwork(bib_sco, analysis = "co-occurrences", network = "keywords", sep = ";")
fig5b <- networkPlot(NetMatrix_keywords, normalize="association", n = 10, 
                     Title = "Keyword Co-occurrences", type = "fruchterman", 
                     size.cex = TRUE, size = 10, remove.multiple = F, 
                     edgesize = 4, labelsize = 3, label.cex = TRUE, 
                     edges.min = 2, label.n = 9, alpha = 0.3) 
```

## fig5c - thematic map based on keywords
```{r}
par(mfrow=c(1,1), mar=c(0,2,0,2))
fig5c <- thematicMap(bib_sco, field = "ID", n = 2000, minfreq = 5, stemming = FALSE, size = 0.5, n.labels = 1, repel = TRUE)
plot(fig5c$map)

```

## fig 5d - author collaboration network
```{r}
NetMatrix_authors <- biblioNetwork(bib_sco, analysis = "collaboration",  network = "authors", sep = ";")
fig5d <- networkPlot(NetMatrix_authors,  n = 100, 
                                      Title = "Author collaboration", 
                                      type = "auto", size = 4, size.cex = TRUE, 
                                      edgesize = 10, labelsize = 1.1)
```

## fig5e - country publications map
```{r}

bibmap <- metaTagExtraction(bib_sco, Field = "AU1_CO", sep = ";") 
bibmap <- metaTagExtraction(bibmap, Field = "AU_CO", sep = ";") 
#save counts in a data frame
firstcountrycounts <- bibmap %>% 
  group_by(AU1_CO) %>%
  count() %>% 
  filter(!is.na(AU1_CO))  
#load map data
world_map <- map_data("world") %>% 
  filter(! long > 180) #remove countries with longitude >180 to make equal projection-like map without artifacts
# Format country names to match regions on the world map
firstcountrycounts$region <- str_to_title(firstcountrycounts$AU1_CO)
firstcountrycounts$region[firstcountrycounts$region == "Usa"] <- "USA" #Fix "Usa" to "USA" :
firstcountrycounts$region[firstcountrycounts$region == "United Kingdom"] <- "UK" #fix to "UK"
#(firstcountrycounts$region) %in% world_map$region #check matching
## colour all regions on the map:
emptymap <- tibble(region = unique(world_map$region), n = rep(0,length(unique(world_map$region)))) #create table with all counts as 0
fullmap <- left_join(emptymap, firstcountrycounts, by = "region") #join with actual counts table
fullmap$n <- fullmap$n.x + fullmap$n.y # make new column for fixed counts
fullmap$n[is.na(fullmap$n)] <- 0 #change NA to 0 for regions with no counts
fig5e <- fullmap %>% 
  ggplot(aes(fill = n, map_id = region)) +
  geom_map(map = world_map, color = "black") +
  expand_limits(x = world_map$long, y = world_map$lat) +
  coord_map("moll") +
  theme(legend.position="right") +
  scale_fill_gradient(low = "#98FB98", high = "#006400",
                    name = "Score", na.value = "gray70",
 limits = c(1, 20),
      guide = guide_colorbar(direction = "vertical.")) +
  guides(fill = guide_colourbar(barwidth = unit(15, units = "mm"), barheight = unit(20, units = "mm")))
fig5e
```

## Map of europe 
```{r}
fig5f <- fullmap %>% 
  ggplot(aes(fill = n, map_id = region)) +
  geom_map(map = world_map, color = "black") +
  coord_map("moll", ylim = c(30, 75), xlim = c(-25, 45)) + # set limits for Europe
  theme(legend.position = "right") +
  scale_fill_gradient(low = "#98FB98", high = "#006400",
                      name = "Score", na.value = "gray70",
                      limits = c(1, 10),
                      guide = guide_colorbar(direction = "vertical.")) +
  guides(fill = guide_colourbar(barwidth = unit(15, units = "mm"), barheight = unit(20, units = "mm")))

fig5f


```

## fig5f - country collaboration network circle plot
```{r}
# Extract countries from the affiliations
bib_sco2 <- metaTagExtraction(bib_sco, Field = "AU_CO", sep = ";")

# Create a network matrix of collaborations between countries
NetMatrix_country <- biblioNetwork(bib_sco2, analysis = "collaboration", network = "countries", sep = ";")

# Convert the network matrix to a standard matrix
NetMatrix_country <- as.matrix(NetMatrix_country)

# Remove the lower triangle (as this is duplication of info)
NetMatrix_country[lower.tri(NetMatrix_country)] <- 0 

# Change column and row names to title case
colnames(NetMatrix_country) <- str_to_title(colnames(NetMatrix_country))
rownames(NetMatrix_country) <- str_to_title(rownames(NetMatrix_country))

# Change "Usa" to "USA"
colnames(NetMatrix_country)[colnames(NetMatrix_country) == "Usa"] <- "USA"
rownames(NetMatrix_country)[rownames(NetMatrix_country) == "Usa"] <- "USA"

# Change "United Kingdom" to "UK" for easier plotting
colnames(NetMatrix_country)[colnames(NetMatrix_country) == "United Kingdom"] <- "UK"
rownames(NetMatrix_country)[rownames(NetMatrix_country) == "United Kingdom"] <- "UK"

# Define colors for each country
my.cols2 <- c(
  USA = "#377eb8",
  Spain = "#ffff33",
  China = "#e41a1c",
  France = "#999999",
  Canada = "#a6cee3",
  Denmark = "#b2df8a",
  Netherlands = "#377eb8",
  Belgium = "#984ea3",
  UK = "#ffff33",
  Australia = "#4daf4a",
  Brazil = "#4daf4a",
  Germany = "#b2df8a",
  Greece = "#f781bf",
  Korea = "#f781bf",
  Ireland = "#a65628",
  Norway = "#ff7f00",
  Sweden = "#4daf4a",
  Egypt = "#f781bf",
  Italy = "#e41a1c",
  Japan = "#1f78b4",
  Switzerland = "#984ea3",
  Turkey = "#33a02c",
  Austria = "#b2df8a",
  Israel = "#f781bf",
  NewZealand = "#4daf4a",
  Russia = "#999999",
  Singapore = "#b2df8a",
  Portugal = "#984ea3",
  Finland = "#b2df8a",
  Mexico = "#a65628",
  Poland = "#b2df8a",
  SouthAfrica = "#f781bf",
  Argentina = "#ff7f00",
  Chile = "#ff7f00",
  CzechRepublic = "#b2df8a",
  Iceland = "#b2df8a",
  Peru = "#ff7f00",
  Romania = "#fb9a99",
  Serbia = "#fb9a99",
  UAE = "#a65628"
)


# Create a chord diagram of the network matrix
fig5f <- chordDiagram(NetMatrix_country, annotationTrack = "grid", preAllocateTracks = 1, grid.col = my.cols2)

# Add a track to label each sector with its name
circos.trackPlotRegion(track.index = 1, panel.fun = function(x, y) {
  xlim = get.cell.meta.data("xlim")
  ylim = get.cell.meta.data("ylim")
  sector.name = get.cell.meta.data("sector.index")
  circos.text(mean(xlim), ylim[1] + .1, sector.name, facing = "clockwise", niceFacing = TRUE, adj = c(0, 0.5))
  circos.axis(h = "top", labels.cex = 0.5, major.tick.length = 0.5, sector.index = sector.name, track.index = 2)
}, bg.border = NA)

```

## fig5g collaboration matrix with self citation removed
```{r}

diag(NetMatrix_country) <- 0

# Create a chord diagram of the network matrix
fig5g <- chordDiagram(NetMatrix_country, annotationTrack = "grid", preAllocateTracks = 1, grid.col = my.cols2)

# Add a track to label each sector with its name
circos.trackPlotRegion(track.index = 1, panel.fun = function(x, y) {
  xlim = get.cell.meta.data("xlim")
  ylim = get.cell.meta.data("ylim")
  sector.name = get.cell.meta.data("sector.index")
  circos.text(mean(xlim), ylim[1] + .1, sector.name, facing = "clockwise", niceFacing = TRUE, adj = c(0, 0.5))
  circos.axis(h = "top", labels.cex = 0.5, major.tick.length = 0.2, sector.index = sector.name, track.index = 2)
}, bg.border = NA)
```

## fig 5h contitnent collaboration 
```{r}


NetMatrix_continent <- NetMatrix_country
colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "USA"] <- "North America"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "USA"] <- "North America"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "Spain"] <- "Europe"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "Spain"] <- "Europe"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "China"] <- "Asia"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "China"] <- "Asia"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "France"] <- "Europe"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "France"] <- "Europe"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "Canada"] <- "North America"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "Canada"] <- "North America"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "Denmark"] <- "Europe"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "Denmark"] <- "Europe"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "Netherlands"] <- "Europe"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "Netherlands"] <- "Europe"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "Belgium"] <- "Europe"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "Belgium"] <- "Europe"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "UK"] <- "Europe"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "UK"] <- "Europe"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "Australia"] <- "Australia"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "Australia"] <- "Australia"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "Brazil"] <- "South America"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "Brazil"] <- "South America"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "Germany"] <- "Europe"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "Germany"] <- "Europe"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "Finland"] <- "Europe"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "Finland"] <- "Europe"


colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "Greece"] <- "Europe"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "Greece"] <- "Europe"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "Korea"] <- "Asia"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "Korea"] <- "Asia"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "Norway"] <- "Europe"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "Norway"] <- "Europe"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "Sweden"] <- "Europe"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "Sweden"] <- "Europe"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "Egypt"] <- "Africa"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "Egypt"] <- "Africa"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "Italy"] <- "Europe"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "Italy"] <- "Europe"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "Japan"] <- "Asia"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "Japan"] <- "Asia"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "Portugal"] <- "Europe"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "Portugal"] <- "Europe"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "Switzerland"] <- "Europe"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "Switzerland"] <- "Europe"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "Turkey"] <- "Asia"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "Turkey"] <- "Asia"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "India"] <- "Asia"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "India"] <- "Asia"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "Iran"] <- "Asia"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "Iran"] <- "Asia"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "Costa Rica"] <- "North America"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "Costa Rica"] <- "North America"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "Czech Republic"] <- "Europe"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "Czech Republic"] <- "Europe"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "Hong Kong"] <- "Asia"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "Hong Kong"] <- "Asia"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "Iceland"] <- "Europe"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "Iceland"] <- "Europe"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "Ireland"] <- "Europe"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "Ireland"] <- "Europe"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "Mexico"] <- "North America"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "Mexico"] <- "North America"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "Romania"] <- "Europe"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "Romania"] <- "Europe"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "Slovakia"] <- "Europe"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "Slovakia"] <- "Europe"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "Ukraine"] <- "Europe"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "Ukraine"] <- "Europe"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "Australia"] <- "Oceania"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "Australia"] <- "Oceania"

colnames(NetMatrix_continent)[colnames(NetMatrix_continent) == "Kazakhstan"] <- "Asia"
rownames(NetMatrix_continent)[rownames(NetMatrix_continent) == "Kazakhstan"] <- "Asia"


# collapsing
merge_matrix <- t(rowsum(t(NetMatrix_continent), group = colnames(NetMatrix_continent), na.rm = T))
merge_matrix2 <- rowsum(merge_matrix, group = rownames(merge_matrix))
# remove diagonal elements
diag(merge_matrix2) <- 0
# chord plot
chordDiagramFromMatrix(merge_matrix2)

# Define colors for each continent
my.cols2 <- c(
  Africa = "#CC79A7",
  NorthAmerica = "#F0E442",
  Asia = "#0072B2",
  Europe = "#E69F00",
  Oceania = "#009E73",
  SouthAmerica = "#D55E00"
)


# Create a chord diagram of the network matrix
fig5h <- chordDiagram(merge_matrix2, annotationTrack = "grid", preAllocateTracks = 1)
# Add a track to label each sector with its name
circos.trackPlotRegion(track.index = 1, panel.fun = function(x, y) {
  xlim = get.cell.meta.data("xlim")
  ylim = get.cell.meta.data("ylim")
  sector.name = get.cell.meta.data("sector.index")
  circos.text(mean(xlim), ylim[1] + 0.2, sector.name, facing = "clockwise", niceFacing = TRUE, adj = c(0, 0.5))
  circos.axis(h = "top", labels.cex = 0.5, major.tick.length = 0.2, sector.index = sector.name, track.index = 2)
}, bg.border = NA)

```

```{r}
Publication_info_discipline <- left_join(sd, sub, by = "study_id")
# matching with 1st author and title
# mapping data
library(stringi)

fields <- Publication_info_discipline %>%
  mutate(title = tolower(unlist(lapply(data.frame(t(stri_split_fixed(paper_title, " ", n = 15)[,1:14])), 
                                       function(x) stri_c(x, collapse  = " ")))),
         ntitle = paste(tolower(stri_split_fixed(study_id, "\\_", n = 2)[,1]), title, sep = " "),
         ntitle = trimws(ntitle)) %>% 
  select(ntitle, subject)


# bib data
Bib_names <- bib_sco %>% rownames_to_column(., var = "mat_names") %>% 
  mutate(TI2 = tolower(unlist(lapply(data.frame(t(str_split_fixed(TI, " ", n = 15)[,1:14])), 
                                     function(x) str_c(x, collapse  = " ")))),
         # stri_trans_general = getting rid of special letters
         name2 = stri_trans_general(tolower(str_split_fixed(SR, " ", n = 2)[,1]), "latin-ascii"),
         TI2 = paste(name2, TI2, sep= " "),
         TI2 = trimws(TI2)) %>% 
  select(TI2, mat_names)


#stringdist(Bib_names$TI2, Fields$ntitle[1], method = 'osa')
pos <- lapply(Bib_names$TI2, function(x) stringdist(fields$ntitle, x))
pos2<- map_dbl(pos, which.min)
# these are looking good - both have the perfect matches (at least at a glance)
Bib_names$TI2
Fields$ntitle[pos2]
# now we can merge two datasets 
Bib_names$discipline_code <- Fields$discipline_code[pos2]
# Creating matrix for bibliometric coupling
NetMatrix <- biblioNetwork(bib, analysis = "coupling", network = "references", sep = ";")
# forcing into a nromal matrix
net_matrix <- as.matrix(NetMatrix)
diag(net_matrix) <- 0 #get rid of counts for the same papers
# replacing names with discipline_code
rownames(net_matrix) <- Bib_names$discipline_code
colnames(net_matrix) <- Bib_names$discipline_code
# reducing matrix according to discipline_code
rect_matrix<- t(rowsum(t(net_matrix), group = colnames(net_matrix), na.rm = T))
small_matrix <- rowsum(rect_matrix, group = rownames(rect_matrix))
# getting rid of lower triangle (as this is duplication of info)
small_matrix[lower.tri(small_matrix)] <- 0 
```


```{r most cited articles and authors}

CR <- citations(bib_sco, field = "article", sep = ";") #list of most cited articles
 cbind(CR$Cited[1:10]) #ten most cited articles
 
CR <- citations(bib_sco, field = "author", sep = ";")
cbind(CR$Cited[1:10]) #ten most cited authors
``` 

```{r bibliometric coupling network}
NetMatrix_coupling <- biblioNetwork(bib_sco, analysis = "coupling", network = "references", sep = "; ")
NetMatrix_coupling_plot <- networkPlot(NetMatrix_coupling, n = 20, 
                                       Title = "Paper co-citation", type = "fruchterman", size=T, 
                                       remove.multiple=FALSE, labelsize=0.8,edgesize = 5)
```


